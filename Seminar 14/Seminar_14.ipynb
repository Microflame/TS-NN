{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Семинар 15: \"Обучение с подкреплением 2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ФИО: Дорожинский Владислав Игоревич"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  FrozenLake\n",
    "\n",
    "\n",
    "<img src=\"http://vignette2.wikia.nocookie.net/riseoftheguardians/images/4/4c/Jack's_little_sister_on_the_ice.jpg/revision/latest?cb=20141218030206\" alt=\"a random image to attract attention\" style=\"width: 400px;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np \n",
    "import random\n",
    "import cv2\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a single game instance\n",
    "env = gym.make(\"FrozenLake-v0\")\n",
    "\n",
    "#start new game\n",
    "env.reset();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n"
     ]
    }
   ],
   "source": [
    "# display the game state\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### legend\n",
    "\n",
    "![img](https://cdn-images-1.medium.com/max/800/1*MCjDzR-wfMMkS0rPqXSmKw.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1.\n",
    "Подберите значения alpha и epsilon и найдите приближение оптимальной Q-функции для Frozen Lake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class QLearn:\n",
    "    def __init__(self, actions, epsilon=0.1, alpha=0.2, gamma=0.9):\n",
    "        self.q = {}\n",
    "        self.epsilon = epsilon\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.actions = actions\n",
    "\n",
    "    def getQ(self, state, action):\n",
    "        return self.q.get((state, action), 0.0)\n",
    "\n",
    "    def learnQ(self, state, action, reward, value):\n",
    "        oldv = self.q.get((state, action), None)\n",
    "\n",
    "        if oldv is None:\n",
    "            self.q[(state, action)] = reward\n",
    "        else:\n",
    "            self.q[(state, action)] = oldv + self.alpha * (value - oldv)\n",
    "\n",
    "    def chooseAction(self, state, is_eval=False):\n",
    "        if random.random() < self.epsilon and not is_eval:\n",
    "            action = random.choice(self.actions)\n",
    "        else:\n",
    "            q = [self.getQ(state, a) for a in self.actions]\n",
    "            maxQ = max(q)\n",
    "            count = q.count(maxQ)\n",
    "            if count > 1:\n",
    "                best = [i for i in range(len(self.actions)) if q[i] == maxQ]\n",
    "                i = random.choice(best)\n",
    "            else:\n",
    "                i = q.index(maxQ)\n",
    "\n",
    "            action = self.actions[i]\n",
    "        return action\n",
    "\n",
    "    def learn(self, state1, action1, reward, state2):\n",
    "        maxqnew = max([self.getQ(state2, a) for a in self.actions])\n",
    "        self.learnQ(state1, action1, reward, reward + self.gamma*maxqnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_episode_qlearn_learn(env, qlearn, gamma=1.0, render=False):\n",
    "    obs = env.reset()\n",
    "    total_reward = 0\n",
    "    step_idx = 0\n",
    "    while True:\n",
    "        if render:\n",
    "            env.render()\n",
    "        action = qlearn.chooseAction(obs)\n",
    "        obs_new, reward, done, _ = env.step(action)\n",
    "        qlearn.learn(obs, action, reward, obs_new)\n",
    "        obs = obs_new\n",
    "        total_reward += (gamma ** step_idx * reward)\n",
    "        step_idx += 1\n",
    "        if done:\n",
    "            break\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_episode_qlearn(env, qlearn, gamma=1.0, render=False):\n",
    "    obs = env.reset()\n",
    "    total_reward = 0\n",
    "    step_idx = 0\n",
    "    while True:\n",
    "        if render:\n",
    "            env.render()\n",
    "        action = qlearn.chooseAction(obs, is_eval=True)\n",
    "        obs_new, reward, done, _ = env.step(action)\n",
    "        obs = obs_new\n",
    "        total_reward += (gamma ** step_idx * reward)\n",
    "        step_idx += 1\n",
    "        if done:\n",
    "            break\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_qlearn(env, qlearn, gamma=1.0, n=100):\n",
    "    scores = [\n",
    "            run_episode_qlearn(env, qlearn, gamma = gamma, render = False)\n",
    "            for _ in range(n)]\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GAMMA = 0.99\n",
    "qlearn = QLearn(actions=range(env.env.nA), gamma=GAMMA, epsilon=0.1, alpha=0.3)\n",
    "[run_episode_qlearn_learn(env, qlearn, gamma=GAMMA) for _ in range(1000)];\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.759"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_qlearn(env, qlearn, gamma=1.0, n=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Задание 2.\n",
    "Обучите сеть DQN для среды http://gym.openai.com/envs/Pong-v0/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* http://www.pinchofintelligence.com/introduction-openai-gym-part-2-building-deep-q-network/\n",
    "* http://www.pinchofintelligence.com/openai-gym-part-3-playing-space-invaders-deep-reinforcement-learning/\n",
    "* https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env = gym.make('Pong-v0')\n",
    "env.reset()\n",
    "actions = env.action_space.n # 0 - idle, 4 - move up, 5 - move down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "act_up, act_down, act_idle = 4, 5, 0\n",
    "actions_mapping = [act_idle, act_up, act_down]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SHORT_MEMORY_SIZE = 4\n",
    "N_ACTIONS = len(actions_mapping)\n",
    "IMAGE_DIM = 84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before processing: (210, 160, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANEAAAD8CAYAAADpCEEHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After processing: (84, 84, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIIMvNcjgSw0y+FKDDL7UIIMvNej/AKb0SsnSiBqbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def one_hot(x, n_classes, dtype=np.float64):\n",
    "    res = np.zeros([x.shape[0], n_classes], dtype=dtype)\n",
    "    res[np.arange(x.shape[0]), x] = 1\n",
    "    return res\n",
    "\n",
    "def preprocess(observation):\n",
    "    head_cut = 32\n",
    "    tail_cut = 15\n",
    "    target_size = IMAGE_DIM\n",
    "    observation = cv2.cvtColor(observation, cv2.COLOR_BGR2GRAY)\n",
    "    observation = cv2.resize(observation[head_cut:-tail_cut], (target_size, target_size))\n",
    "#     ret, observation = cv2.threshold(observation,80,255,cv2.THRESH_BINARY)\n",
    "    return np.reshape(observation,(target_size,target_size,1))\n",
    "\n",
    "def show(img):\n",
    "    plt.imshow(np.array(np.squeeze(img)), cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "action0 = 0  # do nothing\n",
    "observation0, reward0, terminal, info = env.step(action0)\n",
    "print(\"Before processing: \" + str(np.array(observation0).shape))\n",
    "plt.imshow(np.array(observation0))\n",
    "plt.show()\n",
    "observation0 = preprocess(observation0)\n",
    "print(\"After processing: \" + str(np.array(observation0).shape))\n",
    "show(observation0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, in_channels, output_size):\n",
    "        super(DQN, self).__init__()\n",
    "        self.features = nn.Sequential(nn.Conv2d(in_channels, 16, 8, stride=4),\n",
    "                                      nn.BatchNorm2d(16),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.Conv2d(16, 32, 4, stride=2),\n",
    "                                      nn.BatchNorm2d(32),\n",
    "                                      nn.ReLU(),\n",
    "                                     )\n",
    "        \n",
    "        self.classifier = nn.Sequential(nn.Linear(32 * 9 * 9, 256),\n",
    "                                        nn.BatchNorm1d(256),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Linear(256, output_size)\n",
    "                                       )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        x = self.features(x)\n",
    "        x = x.view(-1, 32 * 9 * 9)\n",
    "        x = -self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INITIAL_EPSILON = 1.0\n",
    "FINAL_EPSILON = 0.1\n",
    "M = 16\n",
    "EXPLORE = 1000000 // M\n",
    "REPLAY_MEMORY = 1000000 // M\n",
    "BATCH_SIZE = 32 * M\n",
    "PRINT_EVERY = 100\n",
    "GAMMA = 0.9\n",
    "ALPHA = 1.0\n",
    "K = 4\n",
    "\n",
    "class Controller:\n",
    "    def __init__(self, verbose=False):\n",
    "        self.epsilon = INITIAL_EPSILON\n",
    "        self.verbose = verbose\n",
    "        self.dqn = DQN(SHORT_MEMORY_SIZE, N_ACTIONS).cuda()\n",
    "        self.optimizer = torch.optim.RMSprop(self.dqn.parameters(), lr=0.001)\n",
    "        self.loss_f = nn.MSELoss()\n",
    "        self.step = 0\n",
    "        self.backshift = 0\n",
    "        self.replay = deque()\n",
    "        self.states = deque()\n",
    "        \n",
    "        self.cur_obs = np.zeros([IMAGE_DIM, IMAGE_DIM])\n",
    "        \n",
    "    def train_step(self):\n",
    "        self.dqn.train()\n",
    "        batch_idxs = np.random.randint(4, len(self.replay)-1, BATCH_SIZE)\n",
    "        state_batch = np.zeros([BATCH_SIZE, IMAGE_DIM, IMAGE_DIM, SHORT_MEMORY_SIZE], dtype=np.float32)\n",
    "        action_batch = np.zeros([BATCH_SIZE], dtype=np.int32)\n",
    "        term_batch = np.zeros([BATCH_SIZE], dtype=np.int32)\n",
    "        reward_batch = np.zeros([BATCH_SIZE], dtype=np.float32)\n",
    "        y_reward_batch = np.zeros([BATCH_SIZE], dtype=np.float32)\n",
    "        next_state_batch = np.zeros([BATCH_SIZE, IMAGE_DIM, IMAGE_DIM, SHORT_MEMORY_SIZE], dtype=np.float32)\n",
    "        \n",
    "        for i in range(BATCH_SIZE): # todo: vectorize\n",
    "            idx = batch_idxs[i]\n",
    "            action_batch[i] = self.replay[idx][1]\n",
    "            reward_batch[i] = self.replay[idx][2]\n",
    "            term_batch[i] = self.replay[idx][3]\n",
    "            for j in range(SHORT_MEMORY_SIZE):\n",
    "                state_batch[i,:,:,j] = self.states[idx - j]\n",
    "                next_state_batch[i,:,:,j] = self.states[idx - j + 1]\n",
    "        \n",
    "        next_state_batch = Variable(torch.FloatTensor(next_state_batch)).cuda()\n",
    "        reward_batch = torch.FloatTensor(reward_batch).cuda()\n",
    "        term_batch = torch.FloatTensor(term_batch).cuda()\n",
    "        q_values_pred = self.dqn(next_state_batch)\n",
    "        q_values_pred = torch.max(q_values_pred, 1)[0].data\n",
    "        y_reward_batch = reward_batch + q_values_pred * term_batch\n",
    "        y_reward_batch = Variable(y_reward_batch)\n",
    "                \n",
    "        action_batch = one_hot(action_batch, N_ACTIONS)\n",
    "        action_batch = torch.FloatTensor(action_batch).cuda()\n",
    "        state_batch = Variable(torch.FloatTensor(state_batch)).cuda()\n",
    "        \n",
    "        q_values_pred = self.dqn(state_batch)\n",
    "        q_act_vales = torch.sum(q_values_pred * action_batch, 1)\n",
    "        loss = self.loss_f(q_act_vales, y_reward_batch)\n",
    "        loss.backward()\n",
    "        \n",
    "        self.optimizer.step()\n",
    "        self.dqn.zero_grad()\n",
    "        \n",
    "        if self.step % PRINT_EVERY == 0:\n",
    "            rew_true = reward_batch.cpu().data.numpy()\n",
    "            rew_true_mean = np.mean(rew_true)\n",
    "            rew_true_stat = np.min(rew_true), np.max(rew_true)\n",
    "            rew_true = (y_reward_batch.cpu().data.numpy() < -0.5)\n",
    "            true_n = np.sum(rew_true)\n",
    "            rew_pred = q_act_vales.cpu().data.numpy()\n",
    "            rew_pred_mean = np.mean(rew_pred)\n",
    "            rew_pred = (rew_pred < -0.5)\n",
    "            pred_n = np.sum(rew_pred)\n",
    "            hit_n = np.sum(rew_true & (rew_pred == rew_true))\n",
    "            res_str = '[{}] Loss: {:.4f} TrueN: {} PredN: {} HitNegN: {} PredRew: {:.4f} ActRew: {:.4f} Eps: {:.3f}'\n",
    "            print(res_str.format(self.step,\n",
    "                                 loss.item(),\n",
    "                                 true_n,\n",
    "                                 pred_n,\n",
    "                                 hit_n,\n",
    "                                 rew_pred_mean,\n",
    "                                 rew_true_mean,\n",
    "                                 self.epsilon\n",
    "                                ))\n",
    "\n",
    "            \n",
    "        \n",
    "    def get_action(self):\n",
    "        action = -1\n",
    "        if random.random() <= self.epsilon or len(self.states) < SHORT_MEMORY_SIZE:\n",
    "            action = np.random.randint(N_ACTIONS)\n",
    "        else:\n",
    "            state_batch = np.zeros([1, IMAGE_DIM, IMAGE_DIM, SHORT_MEMORY_SIZE], dtype=np.float32)\n",
    "            idx = len(self.states) - 1\n",
    "            for j in range(SHORT_MEMORY_SIZE):\n",
    "                state_batch[0,:,:,j] = self.states[idx - j]\n",
    "            state_batch = Variable(torch.FloatTensor(state_batch)).cuda()\n",
    "            self.dqn.eval()\n",
    "            qs = self.dqn(state_batch).cpu().data.numpy()[0]\n",
    "            action = np.argmax(qs)\n",
    "        \n",
    "        self.epsilon = INITIAL_EPSILON - (INITIAL_EPSILON - FINAL_EPSILON) \\\n",
    "            * self.step / EXPLORE if self.epsilon > FINAL_EPSILON else FINAL_EPSILON\n",
    "        \n",
    "        return action\n",
    "    \n",
    "    def observe(self, new_obs, action, reward, is_terminal):\n",
    "        self.replay.append((self.step, action, reward, is_terminal))\n",
    "        self.states.append(self.cur_obs)\n",
    "        if len(self.replay) > REPLAY_MEMORY: \n",
    "            self.replay.popleft()\n",
    "            self.states.popleft()\n",
    "        if self.step > SHORT_MEMORY_SIZE:\n",
    "            self.train_step()\n",
    "        \n",
    "        self.cur_obs = new_obs\n",
    "        self.step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ctrl = Controller()\n",
    "env.reset();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100] Loss: 0.0006 TrueN: 16 PredN: 16 HitNegN: 16 PredRew: -0.0343 ActRew: -0.0312 Eps: 0.999\n",
      "[200] Loss: 0.0011 TrueN: 13 PredN: 13 HitNegN: 13 PredRew: -0.0340 ActRew: -0.0254 Eps: 0.997\n",
      "[300] Loss: 0.0059 TrueN: 15 PredN: 13 HitNegN: 13 PredRew: -0.0214 ActRew: -0.0293 Eps: 0.996\n",
      "[400] Loss: 0.0017 TrueN: 14 PredN: 15 HitNegN: 14 PredRew: -0.0314 ActRew: -0.0273 Eps: 0.994\n",
      "[500] Loss: 0.0029 TrueN: 9 PredN: 10 HitNegN: 9 PredRew: -0.0270 ActRew: -0.0176 Eps: 0.993\n",
      "[600] Loss: 0.0010 TrueN: 14 PredN: 14 HitNegN: 14 PredRew: -0.0317 ActRew: -0.0273 Eps: 0.991\n",
      "[700] Loss: 0.0011 TrueN: 10 PredN: 10 HitNegN: 10 PredRew: -0.0341 ActRew: -0.0195 Eps: 0.990\n",
      "[800] Loss: 0.0021 TrueN: 12 PredN: 12 HitNegN: 12 PredRew: -0.0033 ActRew: -0.0234 Eps: 0.988\n",
      "[900] Loss: 0.0026 TrueN: 10 PredN: 8 HitNegN: 8 PredRew: -0.0155 ActRew: -0.0195 Eps: 0.987\n",
      "[1000] Loss: 0.0016 TrueN: 13 PredN: 12 HitNegN: 12 PredRew: -0.0039 ActRew: -0.0254 Eps: 0.986\n",
      "[1100] Loss: 0.0006 TrueN: 12 PredN: 12 HitNegN: 12 PredRew: -0.0353 ActRew: -0.0234 Eps: 0.984\n",
      "[1200] Loss: 0.0035 TrueN: 11 PredN: 11 HitNegN: 11 PredRew: -0.0227 ActRew: -0.0215 Eps: 0.983\n",
      "[1300] Loss: 0.0008 TrueN: 11 PredN: 11 HitNegN: 11 PredRew: -0.0269 ActRew: -0.0215 Eps: 0.981\n",
      "[1400] Loss: 0.0007 TrueN: 16 PredN: 16 HitNegN: 16 PredRew: -0.0298 ActRew: -0.0312 Eps: 0.980\n",
      "[1500] Loss: 0.0012 TrueN: 15 PredN: 15 HitNegN: 15 PredRew: -0.0300 ActRew: -0.0293 Eps: 0.978\n",
      "[1600] Loss: 0.0006 TrueN: 10 PredN: 10 HitNegN: 10 PredRew: -0.0202 ActRew: -0.0195 Eps: 0.977\n",
      "[1700] Loss: 0.0005 TrueN: 13 PredN: 13 HitNegN: 13 PredRew: -0.0288 ActRew: -0.0254 Eps: 0.976\n",
      "[1800] Loss: 0.0013 TrueN: 9 PredN: 9 HitNegN: 9 PredRew: -0.0380 ActRew: -0.0176 Eps: 0.974\n",
      "[1900] Loss: 0.0010 TrueN: 12 PredN: 13 HitNegN: 12 PredRew: -0.0329 ActRew: -0.0234 Eps: 0.973\n",
      "[2000] Loss: 0.0017 TrueN: 9 PredN: 9 HitNegN: 9 PredRew: -0.0392 ActRew: -0.0176 Eps: 0.971\n",
      "[2100] Loss: 0.0008 TrueN: 8 PredN: 8 HitNegN: 8 PredRew: -0.0205 ActRew: -0.0156 Eps: 0.970\n",
      "[2200] Loss: 0.0009 TrueN: 14 PredN: 14 HitNegN: 14 PredRew: -0.0176 ActRew: -0.0273 Eps: 0.968\n",
      "[2300] Loss: 0.0005 TrueN: 12 PredN: 12 HitNegN: 12 PredRew: -0.0215 ActRew: -0.0234 Eps: 0.967\n",
      "[2400] Loss: 0.0021 TrueN: 16 PredN: 16 HitNegN: 16 PredRew: 0.0020 ActRew: -0.0312 Eps: 0.965\n",
      "[2500] Loss: 0.0015 TrueN: 14 PredN: 12 HitNegN: 12 PredRew: -0.0217 ActRew: -0.0273 Eps: 0.964\n",
      "[2600] Loss: 0.0018 TrueN: 13 PredN: 13 HitNegN: 13 PredRew: -0.0294 ActRew: -0.0254 Eps: 0.963\n",
      "[2700] Loss: 0.0004 TrueN: 10 PredN: 10 HitNegN: 10 PredRew: -0.0084 ActRew: -0.0195 Eps: 0.961\n",
      "[2800] Loss: 0.0004 TrueN: 10 PredN: 10 HitNegN: 10 PredRew: -0.0224 ActRew: -0.0195 Eps: 0.960\n",
      "[2900] Loss: 0.0014 TrueN: 19 PredN: 19 HitNegN: 19 PredRew: -0.0269 ActRew: -0.0371 Eps: 0.958\n",
      "[3000] Loss: 0.0009 TrueN: 15 PredN: 14 HitNegN: 14 PredRew: -0.0264 ActRew: -0.0293 Eps: 0.957\n",
      "[3100] Loss: 0.0010 TrueN: 19 PredN: 18 HitNegN: 18 PredRew: -0.0281 ActRew: -0.0371 Eps: 0.955\n",
      "[3200] Loss: 0.0008 TrueN: 14 PredN: 13 HitNegN: 13 PredRew: -0.0248 ActRew: -0.0273 Eps: 0.954\n",
      "[3300] Loss: 0.0009 TrueN: 10 PredN: 9 HitNegN: 9 PredRew: -0.0181 ActRew: -0.0195 Eps: 0.952\n",
      "[3400] Loss: 0.0003 TrueN: 7 PredN: 7 HitNegN: 7 PredRew: -0.0214 ActRew: -0.0137 Eps: 0.951\n",
      "[3500] Loss: 0.0003 TrueN: 10 PredN: 10 HitNegN: 10 PredRew: -0.0197 ActRew: -0.0195 Eps: 0.950\n",
      "[3600] Loss: 0.0004 TrueN: 12 PredN: 12 HitNegN: 12 PredRew: -0.0252 ActRew: -0.0234 Eps: 0.948\n",
      "[3700] Loss: 0.0016 TrueN: 14 PredN: 13 HitNegN: 13 PredRew: -0.0288 ActRew: -0.0273 Eps: 0.947\n",
      "[3800] Loss: 0.0009 TrueN: 7 PredN: 7 HitNegN: 7 PredRew: -0.0214 ActRew: -0.0137 Eps: 0.945\n",
      "[3900] Loss: 0.0007 TrueN: 13 PredN: 13 HitNegN: 13 PredRew: -0.0202 ActRew: -0.0254 Eps: 0.944\n",
      "[4000] Loss: 0.0001 TrueN: 12 PredN: 12 HitNegN: 12 PredRew: -0.0236 ActRew: -0.0234 Eps: 0.942\n",
      "[4100] Loss: 0.0002 TrueN: 11 PredN: 11 HitNegN: 11 PredRew: -0.0201 ActRew: -0.0215 Eps: 0.941\n",
      "[4200] Loss: 0.0008 TrueN: 11 PredN: 11 HitNegN: 11 PredRew: -0.0189 ActRew: -0.0215 Eps: 0.940\n",
      "[4300] Loss: 0.0001 TrueN: 10 PredN: 10 HitNegN: 10 PredRew: -0.0203 ActRew: -0.0195 Eps: 0.938\n",
      "[4400] Loss: 0.0002 TrueN: 8 PredN: 8 HitNegN: 8 PredRew: -0.0111 ActRew: -0.0156 Eps: 0.937\n",
      "[4500] Loss: 0.0003 TrueN: 7 PredN: 7 HitNegN: 7 PredRew: -0.0225 ActRew: -0.0137 Eps: 0.935\n",
      "[4600] Loss: 0.0003 TrueN: 8 PredN: 8 HitNegN: 8 PredRew: -0.0223 ActRew: -0.0156 Eps: 0.934\n",
      "[4700] Loss: 0.0002 TrueN: 11 PredN: 11 HitNegN: 11 PredRew: -0.0191 ActRew: -0.0215 Eps: 0.932\n",
      "[4800] Loss: 0.0006 TrueN: 5 PredN: 5 HitNegN: 5 PredRew: -0.0201 ActRew: -0.0098 Eps: 0.931\n",
      "[4900] Loss: 0.0009 TrueN: 16 PredN: 16 HitNegN: 16 PredRew: -0.0235 ActRew: -0.0312 Eps: 0.929\n",
      "[5000] Loss: 0.0003 TrueN: 13 PredN: 13 HitNegN: 13 PredRew: -0.0292 ActRew: -0.0254 Eps: 0.928\n",
      "[5100] Loss: 0.0006 TrueN: 9 PredN: 9 HitNegN: 9 PredRew: -0.0204 ActRew: -0.0176 Eps: 0.927\n",
      "[5200] Loss: 0.0003 TrueN: 7 PredN: 7 HitNegN: 7 PredRew: -0.0200 ActRew: -0.0137 Eps: 0.925\n",
      "[5300] Loss: 0.0006 TrueN: 11 PredN: 11 HitNegN: 11 PredRew: -0.0251 ActRew: -0.0215 Eps: 0.924\n",
      "[5400] Loss: 0.0004 TrueN: 9 PredN: 9 HitNegN: 9 PredRew: -0.0128 ActRew: -0.0176 Eps: 0.922\n",
      "[5500] Loss: 0.0001 TrueN: 14 PredN: 14 HitNegN: 14 PredRew: -0.0260 ActRew: -0.0273 Eps: 0.921\n",
      "[5600] Loss: 0.0006 TrueN: 11 PredN: 11 HitNegN: 11 PredRew: -0.0259 ActRew: -0.0215 Eps: 0.919\n",
      "[5700] Loss: 0.0010 TrueN: 10 PredN: 10 HitNegN: 10 PredRew: -0.0216 ActRew: -0.0195 Eps: 0.918\n",
      "[5800] Loss: 0.0006 TrueN: 11 PredN: 11 HitNegN: 11 PredRew: -0.0204 ActRew: -0.0215 Eps: 0.916\n",
      "[5900] Loss: 0.0012 TrueN: 10 PredN: 11 HitNegN: 10 PredRew: -0.0161 ActRew: -0.0195 Eps: 0.915\n",
      "[6000] Loss: 0.0002 TrueN: 6 PredN: 6 HitNegN: 6 PredRew: -0.0092 ActRew: -0.0117 Eps: 0.914\n",
      "[6100] Loss: 0.0005 TrueN: 11 PredN: 11 HitNegN: 11 PredRew: -0.0184 ActRew: -0.0215 Eps: 0.912\n",
      "[6200] Loss: 0.0006 TrueN: 6 PredN: 5 HitNegN: 5 PredRew: -0.0106 ActRew: -0.0117 Eps: 0.911\n",
      "[6300] Loss: 0.0002 TrueN: 8 PredN: 8 HitNegN: 8 PredRew: -0.0179 ActRew: -0.0156 Eps: 0.909\n",
      "[6400] Loss: 0.0001 TrueN: 11 PredN: 11 HitNegN: 11 PredRew: -0.0199 ActRew: -0.0215 Eps: 0.908\n",
      "[6500] Loss: 0.0010 TrueN: 13 PredN: 12 HitNegN: 12 PredRew: -0.0296 ActRew: -0.0254 Eps: 0.906\n",
      "[6600] Loss: 0.0012 TrueN: 11 PredN: 10 HitNegN: 10 PredRew: -0.0217 ActRew: -0.0215 Eps: 0.905\n",
      "[6700] Loss: 0.0002 TrueN: 11 PredN: 11 HitNegN: 11 PredRew: -0.0210 ActRew: -0.0215 Eps: 0.904\n",
      "[6800] Loss: 0.0009 TrueN: 13 PredN: 13 HitNegN: 13 PredRew: -0.0255 ActRew: -0.0254 Eps: 0.902\n",
      "[6900] Loss: 0.0002 TrueN: 13 PredN: 13 HitNegN: 13 PredRew: -0.0257 ActRew: -0.0254 Eps: 0.901\n",
      "[7000] Loss: 0.0008 TrueN: 15 PredN: 15 HitNegN: 15 PredRew: -0.0282 ActRew: -0.0293 Eps: 0.899\n",
      "[7100] Loss: 0.0004 TrueN: 9 PredN: 9 HitNegN: 9 PredRew: -0.0142 ActRew: -0.0176 Eps: 0.898\n",
      "[7200] Loss: 0.0003 TrueN: 4 PredN: 4 HitNegN: 4 PredRew: -0.0076 ActRew: -0.0078 Eps: 0.896\n",
      "[7300] Loss: 0.0013 TrueN: 6 PredN: 8 HitNegN: 6 PredRew: -0.0115 ActRew: -0.0117 Eps: 0.895\n",
      "[7400] Loss: 0.0017 TrueN: 10 PredN: 11 HitNegN: 10 PredRew: -0.0220 ActRew: -0.0195 Eps: 0.893\n",
      "[7500] Loss: 0.0004 TrueN: 12 PredN: 12 HitNegN: 12 PredRew: -0.0268 ActRew: -0.0234 Eps: 0.892\n",
      "[7600] Loss: 0.0010 TrueN: 7 PredN: 6 HitNegN: 6 PredRew: -0.0140 ActRew: -0.0137 Eps: 0.891\n",
      "[7700] Loss: 0.0002 TrueN: 9 PredN: 9 HitNegN: 9 PredRew: -0.0173 ActRew: -0.0176 Eps: 0.889\n",
      "[7800] Loss: 0.0006 TrueN: 10 PredN: 10 HitNegN: 10 PredRew: -0.0206 ActRew: -0.0195 Eps: 0.888\n",
      "[7900] Loss: 0.0001 TrueN: 9 PredN: 9 HitNegN: 9 PredRew: -0.0194 ActRew: -0.0176 Eps: 0.886\n",
      "[8000] Loss: 0.0005 TrueN: 14 PredN: 14 HitNegN: 14 PredRew: -0.0219 ActRew: -0.0273 Eps: 0.885\n",
      "[8100] Loss: 0.0001 TrueN: 5 PredN: 5 HitNegN: 5 PredRew: -0.0126 ActRew: -0.0098 Eps: 0.883\n",
      "[8200] Loss: 0.0009 TrueN: 9 PredN: 8 HitNegN: 8 PredRew: -0.0153 ActRew: -0.0176 Eps: 0.882\n",
      "[8300] Loss: 0.0024 TrueN: 14 PredN: 13 HitNegN: 13 PredRew: -0.0318 ActRew: -0.0273 Eps: 0.880\n",
      "[8400] Loss: 0.0012 TrueN: 12 PredN: 11 HitNegN: 11 PredRew: -0.0212 ActRew: -0.0234 Eps: 0.879\n",
      "[8500] Loss: 0.0007 TrueN: 11 PredN: 10 HitNegN: 10 PredRew: -0.0215 ActRew: -0.0215 Eps: 0.878\n",
      "[8600] Loss: 0.0003 TrueN: 10 PredN: 10 HitNegN: 10 PredRew: -0.0164 ActRew: -0.0195 Eps: 0.876\n",
      "[8700] Loss: 0.0013 TrueN: 9 PredN: 10 HitNegN: 9 PredRew: -0.0272 ActRew: -0.0176 Eps: 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8800] Loss: 0.0001 TrueN: 6 PredN: 6 HitNegN: 6 PredRew: -0.0143 ActRew: -0.0117 Eps: 0.873\n",
      "[8900] Loss: 0.0005 TrueN: 11 PredN: 11 HitNegN: 11 PredRew: -0.0254 ActRew: -0.0215 Eps: 0.872\n",
      "[9000] Loss: 0.0009 TrueN: 9 PredN: 9 HitNegN: 9 PredRew: -0.0187 ActRew: -0.0176 Eps: 0.870\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-34bf646b3683>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mactionmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mnew_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_term\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactionmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_term\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mnew_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/MachineLearning/mlenv/lib/python3.5/site-packages/gym/wrappers/time_limit.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_episode_started_at\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Cannot call env.step() before calling reset()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/MachineLearning/mlenv/lib/python3.5/site-packages/gym/envs/atari/atari_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, a)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mnum_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframeskip\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframeskip\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mreward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0male\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/MachineLearning/mlenv/lib/python3.5/site-packages/atari_py/ale_python_interface.py\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0male_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgame_over\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "actionmax = 0\n",
    "for e in range(10000000):\n",
    "    if e % K == 0:\n",
    "        action = ctrl.get_action()\n",
    "        actionmax = np.argmax(np.array(action))\n",
    "    \n",
    "    new_obs, reward, is_term, _ = env.step(actionmax)\n",
    "    if is_term:\n",
    "        new_obs = env.reset()\n",
    "    if e % K == 0:\n",
    "        new_obs = preprocess(new_obs).squeeze()\n",
    "        ctrl.observe(new_obs, action, reward, is_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: 0.0, terminal?: False\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wCsu1aGyr+N4gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANEAAAD8CAYAAADpCEEHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "act = act_idle\n",
    "# act = act_up\n",
    "# act = act_down\n",
    "obs, reward, is_term, _ = env.step(act)\n",
    "print('Reward: {}, terminal?: {}'.format(reward, is_term))\n",
    "show(preprocess(obs))\n",
    "show(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANEAAAD8CAYAAADpCEEHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nySEyS3KIzJIcIrMkh8gs6f8Bp+lHgv4UmYQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
