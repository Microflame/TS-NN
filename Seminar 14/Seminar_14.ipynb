{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Семинар 15: \"Обучение с подкреплением 2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ФИО: Дорожинский Владислав Игоревич"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  FrozenLake\n",
    "\n",
    "\n",
    "<img src=\"http://vignette2.wikia.nocookie.net/riseoftheguardians/images/4/4c/Jack's_little_sister_on_the_ice.jpg/revision/latest?cb=20141218030206\" alt=\"a random image to attract attention\" style=\"width: 400px;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np \n",
    "import random\n",
    "import cv2\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a single game instance\n",
    "env = gym.make(\"FrozenLake-v0\")\n",
    "\n",
    "#start new game\n",
    "env.reset();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n"
     ]
    }
   ],
   "source": [
    "# display the game state\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### legend\n",
    "\n",
    "![img](https://cdn-images-1.medium.com/max/800/1*MCjDzR-wfMMkS0rPqXSmKw.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1.\n",
    "Подберите значения alpha и epsilon и найдите приближение оптимальной Q-функции для Frozen Lake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class QLearn:\n",
    "    def __init__(self, actions, epsilon=0.1, alpha=0.2, gamma=0.9):\n",
    "        self.q = {}\n",
    "        self.epsilon = epsilon\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.actions = actions\n",
    "\n",
    "    def getQ(self, state, action):\n",
    "        return self.q.get((state, action), 0.0)\n",
    "\n",
    "    def learnQ(self, state, action, reward, value):\n",
    "        oldv = self.q.get((state, action), None)\n",
    "\n",
    "        if oldv is None:\n",
    "            self.q[(state, action)] = reward\n",
    "        else:\n",
    "            self.q[(state, action)] = oldv + self.alpha * (value - oldv)\n",
    "\n",
    "    def chooseAction(self, state, is_eval=False):\n",
    "        if random.random() < self.epsilon and not is_eval:\n",
    "            action = random.choice(self.actions)\n",
    "        else:\n",
    "            q = [self.getQ(state, a) for a in self.actions]\n",
    "            maxQ = max(q)\n",
    "            count = q.count(maxQ)\n",
    "            if count > 1:\n",
    "                best = [i for i in range(len(self.actions)) if q[i] == maxQ]\n",
    "                i = random.choice(best)\n",
    "            else:\n",
    "                i = q.index(maxQ)\n",
    "\n",
    "            action = self.actions[i]\n",
    "        return action\n",
    "\n",
    "    def learn(self, state1, action1, reward, state2):\n",
    "        maxqnew = max([self.getQ(state2, a) for a in self.actions])\n",
    "        self.learnQ(state1, action1, reward, reward + self.gamma*maxqnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_episode_qlearn_learn(env, qlearn, gamma=1.0, render=False):\n",
    "    obs = env.reset()\n",
    "    total_reward = 0\n",
    "    step_idx = 0\n",
    "    while True:\n",
    "        if render:\n",
    "            env.render()\n",
    "        action = qlearn.chooseAction(obs)\n",
    "        obs_new, reward, done, _ = env.step(action)\n",
    "        qlearn.learn(obs, action, reward, obs_new)\n",
    "        obs = obs_new\n",
    "        total_reward += (gamma ** step_idx * reward)\n",
    "        step_idx += 1\n",
    "        if done:\n",
    "            break\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_episode_qlearn(env, qlearn, gamma=1.0, render=False):\n",
    "    obs = env.reset()\n",
    "    total_reward = 0\n",
    "    step_idx = 0\n",
    "    while True:\n",
    "        if render:\n",
    "            env.render()\n",
    "        action = qlearn.chooseAction(obs, is_eval=True)\n",
    "        obs_new, reward, done, _ = env.step(action)\n",
    "        obs = obs_new\n",
    "        total_reward += (gamma ** step_idx * reward)\n",
    "        step_idx += 1\n",
    "        if done:\n",
    "            break\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_qlearn(env, qlearn, gamma=1.0, n=100):\n",
    "    scores = [\n",
    "            run_episode_qlearn(env, qlearn, gamma = gamma, render = False)\n",
    "            for _ in range(n)]\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GAMMA = 0.99\n",
    "qlearn = QLearn(actions=range(env.env.nA), gamma=GAMMA, epsilon=0.1, alpha=0.3)\n",
    "[run_episode_qlearn_learn(env, qlearn, gamma=GAMMA) for _ in range(1000)];\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.759"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_qlearn(env, qlearn, gamma=1.0, n=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Задание 2.\n",
    "Обучите сеть DQN для среды http://gym.openai.com/envs/Pong-v0/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* http://www.pinchofintelligence.com/introduction-openai-gym-part-2-building-deep-q-network/\n",
    "* http://www.pinchofintelligence.com/openai-gym-part-3-playing-space-invaders-deep-reinforcement-learning/\n",
    "* https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env = gym.make('Pong-v0')\n",
    "env.reset()\n",
    "actions = env.action_space.n # 0 - idle, 4 - move up, 5 - move down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "act_up, act_down, act_idle = 4, 5, 0\n",
    "actions_mapping = [act_idle, act_up, act_down]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SHORT_MEMORY_SIZE = 4\n",
    "N_ACTIONS = len(actions_mapping)\n",
    "IMAGE_DIM = 84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before processing: (210, 160, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANEAAAD8CAYAAADpCEEHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After processing: (84, 84, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def one_hot(x, n_classes, dtype=np.float64):\n",
    "    res = np.zeros([x.shape[0], n_classes], dtype=dtype)\n",
    "    res[np.arange(x.shape[0]), x] = 1\n",
    "    return res\n",
    "\n",
    "def preprocess(observation):\n",
    "    head_cut = 32\n",
    "    tail_cut = 15\n",
    "    target_size = IMAGE_DIM\n",
    "    observation = cv2.cvtColor(observation, cv2.COLOR_BGR2GRAY)\n",
    "    observation = cv2.resize(observation[head_cut:-tail_cut], (target_size, target_size))\n",
    "#     ret, observation = cv2.threshold(observation,80,255,cv2.THRESH_BINARY)\n",
    "    return np.reshape(observation,(target_size,target_size,1))\n",
    "\n",
    "def show(img):\n",
    "    plt.imshow(np.array(np.squeeze(img)), cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "action0 = 0  # do nothing\n",
    "observation0, reward0, terminal, info = env.step(action0)\n",
    "print(\"Before processing: \" + str(np.array(observation0).shape))\n",
    "plt.imshow(np.array(observation0))\n",
    "plt.show()\n",
    "observation0 = preprocess(observation0)\n",
    "print(\"After processing: \" + str(np.array(observation0).shape))\n",
    "show(observation0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, in_channels, output_size):\n",
    "        super(DQN, self).__init__()\n",
    "        self.features = nn.Sequential(nn.Conv2d(in_channels, 16, 8, stride=4),\n",
    "                                      nn.BatchNorm2d(16),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.Conv2d(16, 32, 4, stride=2),\n",
    "                                      nn.BatchNorm2d(32),\n",
    "                                      nn.ReLU(),\n",
    "                                     )\n",
    "        \n",
    "        self.classifier = nn.Sequential(nn.Linear(32 * 9 * 9, 256),\n",
    "                                        nn.BatchNorm1d(256),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Linear(256, output_size)\n",
    "                                       )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        x = self.features(x)\n",
    "        x = x.view(-1, 32 * 9 * 9)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INITIAL_EPSILON = 1.0\n",
    "FINAL_EPSILON = 0.1\n",
    "EXPLORE = 10000\n",
    "REPLAY_MEMORY = 10000\n",
    "BATCH_SIZE = 128\n",
    "PRINT_EVERY = 500\n",
    "GAMMA = 0.95\n",
    "ALPHA = 1.0\n",
    "K = 4\n",
    "\n",
    "class Controller:\n",
    "    def __init__(self, verbose=False):\n",
    "        self.epsilon = INITIAL_EPSILON\n",
    "        self.verbose = verbose\n",
    "        self.dqn = DQN(SHORT_MEMORY_SIZE, N_ACTIONS).cuda()\n",
    "        self.optimizer = torch.optim.Adam(self.dqn.parameters(), lr=0.001)\n",
    "        self.loss_f = nn.MSELoss()\n",
    "        self.step = 0\n",
    "        self.replay = deque()\n",
    "        self.states = deque()\n",
    "    \n",
    "        \n",
    "    def train_step(self):\n",
    "#         print('>>>ENTER TRAIN STEP')\n",
    "        self.dqn.train()\n",
    "        batch_idxs = np.random.randint(SHORT_MEMORY_SIZE, len(self.replay)-1, BATCH_SIZE)\n",
    "        state_batch = np.zeros([BATCH_SIZE, IMAGE_DIM, IMAGE_DIM, SHORT_MEMORY_SIZE], dtype=np.float32)\n",
    "        action_batch = np.zeros([BATCH_SIZE], dtype=np.int32)\n",
    "        term_batch = np.zeros([BATCH_SIZE], dtype=np.int32)\n",
    "        reward_batch = np.zeros([BATCH_SIZE], dtype=np.float32)\n",
    "        y_reward_batch = np.zeros([BATCH_SIZE], dtype=np.float32)\n",
    "        next_state_batch = np.zeros([BATCH_SIZE, IMAGE_DIM, IMAGE_DIM, SHORT_MEMORY_SIZE], dtype=np.float32)\n",
    "        \n",
    "        for i in range(BATCH_SIZE): # todo: vectorize\n",
    "            idx = batch_idxs[i]\n",
    "            action_batch[i] = self.replay[idx][1]\n",
    "            reward_batch[i] = self.replay[idx][2]\n",
    "            term_batch[i] = self.replay[idx][3]\n",
    "            for j in range(SHORT_MEMORY_SIZE):\n",
    "                state_batch[i,:,:,j] = self.states[idx - j - 1]\n",
    "                next_state_batch[i,:,:,j] = self.states[idx - j]\n",
    "        \n",
    "        next_state_batch = Variable(torch.FloatTensor(next_state_batch)).cuda()\n",
    "        reward_batch = torch.FloatTensor(reward_batch).cuda()\n",
    "        term_batch = torch.FloatTensor(term_batch).cuda()\n",
    "        q_values_pred = self.dqn(next_state_batch)\n",
    "        q_values_pred = torch.max(q_values_pred, 1)[0].data\n",
    "#         print('q_values_pred')\n",
    "#         print(q_values_pred)\n",
    "#         print('term_batch')\n",
    "#         print(term_batch)\n",
    "        y_reward_batch = reward_batch + q_values_pred * (1 - term_batch) * GAMMA\n",
    "        y_reward_batch = Variable(y_reward_batch, requires_grad=False)\n",
    "#         print('y_reward_batch')\n",
    "#         print(y_reward_batch)\n",
    "                \n",
    "        action_batch = one_hot(action_batch, N_ACTIONS)\n",
    "        action_batch = torch.FloatTensor(action_batch).cuda()\n",
    "        \n",
    "        state_batch = Variable(torch.FloatTensor(state_batch)).cuda()\n",
    "        q_values_pred = self.dqn(state_batch)\n",
    "        q_act_vales = torch.sum(q_values_pred * action_batch, 1)\n",
    "#         print('q_act_vales')\n",
    "#         print(q_act_vales)\n",
    "        loss = self.loss_f(q_act_vales, y_reward_batch)\n",
    "        loss.backward()\n",
    "        \n",
    "        self.optimizer.step()\n",
    "        self.dqn.zero_grad()\n",
    "        \n",
    "        if self.step % PRINT_EVERY == 0:\n",
    "            rew_true = reward_batch.cpu().data.numpy()\n",
    "#             print(rew_true[:5])\n",
    "            rew_true_mean = np.mean(rew_true)\n",
    "            rew_true_stat = np.min(rew_true), np.max(rew_true)\n",
    "            rew_true = (y_reward_batch.cpu().data.numpy() < -0.5)\n",
    "            true_n = np.sum(rew_true)\n",
    "            rew_pred = q_act_vales.cpu().data.numpy()\n",
    "#             print(rew_pred[:5])\n",
    "#             print(q_values_pred.cpu().data.numpy()[:5])\n",
    "            rew_pred_mean = np.mean(rew_pred)\n",
    "            rew_pred = (rew_pred < -0.5)\n",
    "            pred_n = np.sum(rew_pred)\n",
    "            hit_n = np.sum(rew_true & (rew_pred == rew_true))\n",
    "            res_str = '[{}] Loss: {:.4f} TrueN: {} PredN: {} HitNegN: {} PredRew: {:.4f} ActRew: {:.4f} Eps: {:.3f}'\n",
    "            print(res_str.format(self.step,\n",
    "                                 loss.item(),\n",
    "                                 true_n,\n",
    "                                 pred_n,\n",
    "                                 hit_n,\n",
    "                                 rew_pred_mean,\n",
    "                                 rew_true_mean,\n",
    "                                 self.epsilon\n",
    "                                ))\n",
    "#         print('<<<EXIT TRAIN STEP\\n')\n",
    "\n",
    "            \n",
    "        \n",
    "    def get_action(self):\n",
    "        action = -1\n",
    "        if random.random() <= self.epsilon or len(self.states) < SHORT_MEMORY_SIZE:\n",
    "            action = np.random.randint(N_ACTIONS)\n",
    "        else:\n",
    "            state_batch = np.zeros([1, IMAGE_DIM, IMAGE_DIM, SHORT_MEMORY_SIZE], dtype=np.float32)\n",
    "            idx = len(self.states) - 1\n",
    "            for j in range(SHORT_MEMORY_SIZE):\n",
    "                state_batch[0,:,:,j] = self.states[idx - j]\n",
    "            state_batch = Variable(torch.FloatTensor(state_batch)).cuda()\n",
    "            self.dqn.eval()\n",
    "            qs = self.dqn(state_batch).cpu().data.numpy()[0]\n",
    "            action = np.argmax(qs)\n",
    "        \n",
    "        self.epsilon = INITIAL_EPSILON - (INITIAL_EPSILON - FINAL_EPSILON) \\\n",
    "            * self.step / EXPLORE if self.epsilon > FINAL_EPSILON else FINAL_EPSILON\n",
    "        \n",
    "        return action\n",
    "    \n",
    "    def observe(self, new_obs, action, reward, is_terminal):\n",
    "        self.replay.append((self.step, action, reward, is_terminal))\n",
    "        self.states.append(new_obs)\n",
    "        if len(self.replay) > REPLAY_MEMORY: \n",
    "            self.replay.popleft()\n",
    "            self.states.popleft()\n",
    "        if self.step > 100:\n",
    "            self.train_step()\n",
    "        \n",
    "        self.step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ctrl = Controller()\n",
    "env.reset();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25000] Loss: 0.0054 TrueN: 8 PredN: 8 HitNegN: 7 PredRew: 0.0327 ActRew: -0.0625 Eps: 0.100\n",
      "[25500] Loss: 0.0013 TrueN: 3 PredN: 2 HitNegN: 2 PredRew: 0.0605 ActRew: -0.0156 Eps: 0.100\n",
      "[26000] Loss: 0.0012 TrueN: 6 PredN: 6 HitNegN: 6 PredRew: 0.0444 ActRew: -0.0391 Eps: 0.100\n",
      "[26500] Loss: 0.0012 TrueN: 1 PredN: 1 HitNegN: 1 PredRew: 0.0627 ActRew: 0.0000 Eps: 0.100\n",
      "[27000] Loss: 0.0014 TrueN: 5 PredN: 5 HitNegN: 5 PredRew: 0.0591 ActRew: -0.0234 Eps: 0.100\n",
      "[27500] Loss: 0.0026 TrueN: 4 PredN: 4 HitNegN: 4 PredRew: 0.0528 ActRew: -0.0156 Eps: 0.100\n",
      "[28000] Loss: 0.0007 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: 0.0641 ActRew: -0.0234 Eps: 0.100\n",
      "[28500] Loss: 0.0012 TrueN: 1 PredN: 1 HitNegN: 1 PredRew: 0.0686 ActRew: -0.0078 Eps: 0.100\n",
      "[29000] Loss: 0.0019 TrueN: 6 PredN: 6 HitNegN: 6 PredRew: 0.0218 ActRew: -0.0391 Eps: 0.100\n",
      "[29500] Loss: 0.0010 TrueN: 2 PredN: 2 HitNegN: 2 PredRew: 0.0603 ActRew: -0.0156 Eps: 0.100\n",
      "[30000] Loss: 0.0006 TrueN: 4 PredN: 4 HitNegN: 4 PredRew: 0.0504 ActRew: -0.0234 Eps: 0.100\n",
      "[30500] Loss: 0.0008 TrueN: 1 PredN: 1 HitNegN: 1 PredRew: 0.0497 ActRew: -0.0078 Eps: 0.100\n",
      "[31000] Loss: 0.0016 TrueN: 3 PredN: 2 HitNegN: 2 PredRew: 0.0650 ActRew: -0.0156 Eps: 0.100\n",
      "[31500] Loss: 0.0019 TrueN: 5 PredN: 4 HitNegN: 4 PredRew: 0.0339 ActRew: -0.0312 Eps: 0.100\n",
      "[32000] Loss: 0.0071 TrueN: 5 PredN: 5 HitNegN: 4 PredRew: 0.0187 ActRew: -0.0391 Eps: 0.100\n",
      "[32500] Loss: 0.0007 TrueN: 4 PredN: 3 HitNegN: 3 PredRew: 0.0356 ActRew: -0.0234 Eps: 0.100\n",
      "[33000] Loss: 0.0012 TrueN: 0 PredN: 0 HitNegN: 0 PredRew: 0.0278 ActRew: 0.0000 Eps: 0.100\n",
      "[33500] Loss: 0.0014 TrueN: 2 PredN: 2 HitNegN: 2 PredRew: 0.0540 ActRew: -0.0156 Eps: 0.100\n",
      "[34000] Loss: 0.0006 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: 0.0442 ActRew: -0.0156 Eps: 0.100\n",
      "[34500] Loss: 0.0073 TrueN: 3 PredN: 4 HitNegN: 3 PredRew: 0.0255 ActRew: -0.0156 Eps: 0.100\n",
      "[35000] Loss: 0.0048 TrueN: 10 PredN: 8 HitNegN: 8 PredRew: -0.0081 ActRew: -0.0625 Eps: 0.100\n",
      "[35500] Loss: 0.0017 TrueN: 1 PredN: 1 HitNegN: 1 PredRew: 0.0337 ActRew: -0.0078 Eps: 0.100\n",
      "[36000] Loss: 0.0017 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: 0.0420 ActRew: -0.0234 Eps: 0.100\n",
      "[36500] Loss: 0.0009 TrueN: 1 PredN: 2 HitNegN: 1 PredRew: 0.0505 ActRew: 0.0000 Eps: 0.100\n",
      "[37000] Loss: 0.0019 TrueN: 1 PredN: 1 HitNegN: 1 PredRew: 0.0470 ActRew: -0.0078 Eps: 0.100\n",
      "[37500] Loss: 0.0069 TrueN: 4 PredN: 3 HitNegN: 3 PredRew: 0.0260 ActRew: -0.0312 Eps: 0.100\n",
      "[38000] Loss: 0.0016 TrueN: 1 PredN: 1 HitNegN: 1 PredRew: 0.0398 ActRew: -0.0078 Eps: 0.100\n",
      "[38500] Loss: 0.0015 TrueN: 4 PredN: 4 HitNegN: 4 PredRew: 0.0287 ActRew: -0.0312 Eps: 0.100\n",
      "[39000] Loss: 0.0029 TrueN: 4 PredN: 4 HitNegN: 4 PredRew: 0.0167 ActRew: -0.0156 Eps: 0.100\n",
      "[39500] Loss: 0.0010 TrueN: 5 PredN: 5 HitNegN: 5 PredRew: 0.0327 ActRew: -0.0312 Eps: 0.100\n",
      "[40000] Loss: 0.0025 TrueN: 1 PredN: 1 HitNegN: 1 PredRew: 0.0623 ActRew: 0.0000 Eps: 0.100\n",
      "[40500] Loss: 0.0013 TrueN: 3 PredN: 4 HitNegN: 3 PredRew: 0.0234 ActRew: -0.0234 Eps: 0.100\n",
      "[41000] Loss: 0.0106 TrueN: 6 PredN: 4 HitNegN: 4 PredRew: 0.0368 ActRew: -0.0391 Eps: 0.100\n",
      "[41500] Loss: 0.0019 TrueN: 1 PredN: 1 HitNegN: 1 PredRew: 0.0692 ActRew: -0.0078 Eps: 0.100\n",
      "[42000] Loss: 0.0026 TrueN: 5 PredN: 5 HitNegN: 5 PredRew: 0.0131 ActRew: -0.0391 Eps: 0.100\n",
      "[42500] Loss: 0.0013 TrueN: 4 PredN: 4 HitNegN: 4 PredRew: 0.0402 ActRew: -0.0234 Eps: 0.100\n",
      "[43000] Loss: 0.0016 TrueN: 4 PredN: 4 HitNegN: 4 PredRew: 0.0365 ActRew: -0.0312 Eps: 0.100\n",
      "[43500] Loss: 0.0019 TrueN: 3 PredN: 2 HitNegN: 2 PredRew: 0.0436 ActRew: -0.0078 Eps: 0.100\n",
      "[44000] Loss: 0.0023 TrueN: 6 PredN: 6 HitNegN: 6 PredRew: 0.0284 ActRew: -0.0391 Eps: 0.100\n",
      "[44500] Loss: 0.0019 TrueN: 4 PredN: 5 HitNegN: 4 PredRew: 0.0307 ActRew: -0.0312 Eps: 0.100\n",
      "[45000] Loss: 0.0007 TrueN: 1 PredN: 1 HitNegN: 1 PredRew: 0.0420 ActRew: -0.0078 Eps: 0.100\n",
      "[45500] Loss: 0.0033 TrueN: 5 PredN: 5 HitNegN: 5 PredRew: 0.0351 ActRew: -0.0391 Eps: 0.100\n",
      "[46000] Loss: 0.0014 TrueN: 1 PredN: 1 HitNegN: 1 PredRew: 0.0560 ActRew: 0.0000 Eps: 0.100\n",
      "[46500] Loss: 0.0014 TrueN: 5 PredN: 5 HitNegN: 5 PredRew: 0.0264 ActRew: -0.0156 Eps: 0.100\n",
      "[47000] Loss: 0.0017 TrueN: 4 PredN: 4 HitNegN: 4 PredRew: 0.0360 ActRew: -0.0234 Eps: 0.100\n",
      "[47500] Loss: 0.0017 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: 0.0365 ActRew: -0.0234 Eps: 0.100\n",
      "[48000] Loss: 0.0009 TrueN: 1 PredN: 1 HitNegN: 1 PredRew: 0.0787 ActRew: -0.0078 Eps: 0.100\n",
      "[48500] Loss: 0.0035 TrueN: 3 PredN: 2 HitNegN: 2 PredRew: 0.0470 ActRew: -0.0078 Eps: 0.100\n",
      "[49000] Loss: 0.0066 TrueN: 4 PredN: 5 HitNegN: 4 PredRew: 0.0291 ActRew: -0.0312 Eps: 0.100\n",
      "[49500] Loss: 0.0083 TrueN: 7 PredN: 5 HitNegN: 5 PredRew: 0.0203 ActRew: -0.0547 Eps: 0.100\n",
      "[50000] Loss: 0.0015 TrueN: 4 PredN: 2 HitNegN: 2 PredRew: 0.0345 ActRew: -0.0156 Eps: 0.100\n",
      "[50500] Loss: 0.0018 TrueN: 4 PredN: 4 HitNegN: 4 PredRew: 0.0361 ActRew: -0.0312 Eps: 0.100\n",
      "[51000] Loss: 0.0009 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: 0.0327 ActRew: -0.0234 Eps: 0.100\n",
      "[51500] Loss: 0.0019 TrueN: 4 PredN: 3 HitNegN: 3 PredRew: 0.0603 ActRew: -0.0156 Eps: 0.100\n",
      "[52000] Loss: 0.0060 TrueN: 4 PredN: 2 HitNegN: 2 PredRew: 0.0362 ActRew: -0.0156 Eps: 0.100\n",
      "[52500] Loss: 0.0050 TrueN: 5 PredN: 4 HitNegN: 4 PredRew: 0.0494 ActRew: -0.0391 Eps: 0.100\n",
      "[53000] Loss: 0.0020 TrueN: 2 PredN: 1 HitNegN: 1 PredRew: 0.0705 ActRew: 0.0000 Eps: 0.100\n",
      "[53500] Loss: 0.0014 TrueN: 2 PredN: 3 HitNegN: 2 PredRew: 0.0445 ActRew: -0.0156 Eps: 0.100\n",
      "[54000] Loss: 0.0027 TrueN: 4 PredN: 3 HitNegN: 3 PredRew: 0.0614 ActRew: -0.0156 Eps: 0.100\n",
      "[54500] Loss: 0.0017 TrueN: 5 PredN: 5 HitNegN: 5 PredRew: 0.0363 ActRew: -0.0234 Eps: 0.100\n",
      "[55000] Loss: 0.0027 TrueN: 3 PredN: 4 HitNegN: 3 PredRew: 0.0365 ActRew: -0.0234 Eps: 0.100\n",
      "[55500] Loss: 0.0007 TrueN: 1 PredN: 1 HitNegN: 1 PredRew: 0.0674 ActRew: 0.0000 Eps: 0.100\n",
      "[56000] Loss: 0.0020 TrueN: 1 PredN: 1 HitNegN: 1 PredRew: 0.0453 ActRew: -0.0078 Eps: 0.100\n",
      "[56500] Loss: 0.0015 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: 0.0520 ActRew: -0.0234 Eps: 0.100\n",
      "[57000] Loss: 0.0011 TrueN: 1 PredN: 1 HitNegN: 1 PredRew: 0.0321 ActRew: 0.0000 Eps: 0.100\n",
      "[57500] Loss: 0.0019 TrueN: 2 PredN: 2 HitNegN: 2 PredRew: 0.0225 ActRew: -0.0078 Eps: 0.100\n",
      "[58000] Loss: 0.0023 TrueN: 12 PredN: 12 HitNegN: 12 PredRew: -0.0548 ActRew: -0.0859 Eps: 0.100\n",
      "[58500] Loss: 0.0024 TrueN: 0 PredN: 0 HitNegN: 0 PredRew: 0.0557 ActRew: 0.0000 Eps: 0.100\n",
      "[59000] Loss: 0.0038 TrueN: 3 PredN: 2 HitNegN: 2 PredRew: 0.0285 ActRew: -0.0078 Eps: 0.100\n",
      "[59500] Loss: 0.0014 TrueN: 7 PredN: 4 HitNegN: 4 PredRew: 0.0246 ActRew: -0.0234 Eps: 0.100\n",
      "[60000] Loss: 0.0014 TrueN: 5 PredN: 5 HitNegN: 5 PredRew: 0.0375 ActRew: -0.0156 Eps: 0.100\n",
      "[60500] Loss: 0.0021 TrueN: 3 PredN: 4 HitNegN: 3 PredRew: 0.0535 ActRew: -0.0078 Eps: 0.100\n",
      "[61000] Loss: 0.0017 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: 0.0630 ActRew: -0.0234 Eps: 0.100\n",
      "[61500] Loss: 0.0019 TrueN: 2 PredN: 1 HitNegN: 1 PredRew: 0.0543 ActRew: -0.0078 Eps: 0.100\n",
      "[62000] Loss: 0.0013 TrueN: 2 PredN: 2 HitNegN: 2 PredRew: 0.0364 ActRew: -0.0156 Eps: 0.100\n",
      "[62500] Loss: 0.0034 TrueN: 5 PredN: 5 HitNegN: 5 PredRew: 0.0418 ActRew: -0.0391 Eps: 0.100\n",
      "[63000] Loss: 0.0012 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: 0.0435 ActRew: -0.0156 Eps: 0.100\n",
      "[63500] Loss: 0.0016 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: 0.0287 ActRew: -0.0234 Eps: 0.100\n",
      "[64000] Loss: 0.0024 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: 0.0448 ActRew: -0.0078 Eps: 0.100\n",
      "[64500] Loss: 0.0031 TrueN: 4 PredN: 3 HitNegN: 3 PredRew: 0.0456 ActRew: -0.0234 Eps: 0.100\n",
      "[65000] Loss: 0.0058 TrueN: 10 PredN: 10 HitNegN: 9 PredRew: -0.0169 ActRew: -0.0547 Eps: 0.100\n",
      "[65500] Loss: 0.0017 TrueN: 0 PredN: 0 HitNegN: 0 PredRew: 0.0547 ActRew: 0.0000 Eps: 0.100\n",
      "[66000] Loss: 0.0011 TrueN: 2 PredN: 3 HitNegN: 2 PredRew: 0.0536 ActRew: -0.0078 Eps: 0.100\n",
      "[66500] Loss: 0.0012 TrueN: 5 PredN: 5 HitNegN: 5 PredRew: 0.0141 ActRew: -0.0391 Eps: 0.100\n",
      "[67000] Loss: 0.0048 TrueN: 6 PredN: 4 HitNegN: 4 PredRew: 0.0402 ActRew: -0.0391 Eps: 0.100\n",
      "[67500] Loss: 0.0013 TrueN: 4 PredN: 4 HitNegN: 4 PredRew: 0.0367 ActRew: -0.0234 Eps: 0.100\n",
      "[68000] Loss: 0.0008 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: 0.0233 ActRew: -0.0156 Eps: 0.100\n",
      "[68500] Loss: 0.0027 TrueN: 4 PredN: 3 HitNegN: 3 PredRew: 0.0183 ActRew: -0.0234 Eps: 0.100\n",
      "[69000] Loss: 0.0045 TrueN: 5 PredN: 4 HitNegN: 3 PredRew: 0.0221 ActRew: -0.0312 Eps: 0.100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[69500] Loss: 0.0029 TrueN: 3 PredN: 2 HitNegN: 2 PredRew: 0.0204 ActRew: -0.0078 Eps: 0.100\n",
      "[70000] Loss: 0.0019 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: 0.0042 ActRew: -0.0156 Eps: 0.100\n",
      "[70500] Loss: 0.0044 TrueN: 5 PredN: 5 HitNegN: 5 PredRew: -0.0041 ActRew: -0.0234 Eps: 0.100\n",
      "[71000] Loss: 0.0025 TrueN: 1 PredN: 1 HitNegN: 1 PredRew: 0.0406 ActRew: 0.0000 Eps: 0.100\n",
      "[71500] Loss: 0.0029 TrueN: 5 PredN: 4 HitNegN: 4 PredRew: -0.0012 ActRew: -0.0312 Eps: 0.100\n",
      "[72000] Loss: 0.0042 TrueN: 10 PredN: 9 HitNegN: 9 PredRew: -0.0286 ActRew: -0.0547 Eps: 0.100\n",
      "[72500] Loss: 0.0041 TrueN: 9 PredN: 8 HitNegN: 8 PredRew: -0.0099 ActRew: -0.0391 Eps: 0.100\n",
      "[73000] Loss: 0.0022 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: 0.0344 ActRew: -0.0078 Eps: 0.100\n",
      "[73500] Loss: 0.0054 TrueN: 3 PredN: 4 HitNegN: 3 PredRew: 0.0286 ActRew: -0.0078 Eps: 0.100\n",
      "[74000] Loss: 0.0022 TrueN: 2 PredN: 1 HitNegN: 1 PredRew: 0.0321 ActRew: -0.0078 Eps: 0.100\n",
      "[74500] Loss: 0.0056 TrueN: 4 PredN: 3 HitNegN: 3 PredRew: 0.0127 ActRew: -0.0234 Eps: 0.100\n",
      "[75000] Loss: 0.0017 TrueN: 6 PredN: 6 HitNegN: 6 PredRew: 0.0065 ActRew: -0.0234 Eps: 0.100\n",
      "[75500] Loss: 0.0026 TrueN: 1 PredN: 1 HitNegN: 1 PredRew: 0.0510 ActRew: -0.0078 Eps: 0.100\n",
      "[76000] Loss: 0.0017 TrueN: 3 PredN: 4 HitNegN: 3 PredRew: 0.0229 ActRew: -0.0078 Eps: 0.100\n",
      "[76500] Loss: 0.0027 TrueN: 3 PredN: 2 HitNegN: 2 PredRew: 0.0175 ActRew: -0.0078 Eps: 0.100\n",
      "[77000] Loss: 0.0018 TrueN: 6 PredN: 5 HitNegN: 5 PredRew: 0.0135 ActRew: -0.0312 Eps: 0.100\n",
      "[77500] Loss: 0.0048 TrueN: 1 PredN: 0 HitNegN: 0 PredRew: 0.0383 ActRew: 0.0000 Eps: 0.100\n",
      "[78000] Loss: 0.0077 TrueN: 5 PredN: 2 HitNegN: 2 PredRew: 0.0084 ActRew: -0.0156 Eps: 0.100\n",
      "[78500] Loss: 0.0018 TrueN: 3 PredN: 4 HitNegN: 3 PredRew: 0.0559 ActRew: -0.0078 Eps: 0.100\n",
      "[79000] Loss: 0.0071 TrueN: 8 PredN: 6 HitNegN: 6 PredRew: 0.0152 ActRew: -0.0547 Eps: 0.100\n",
      "[79500] Loss: 0.0021 TrueN: 5 PredN: 5 HitNegN: 5 PredRew: 0.0439 ActRew: -0.0234 Eps: 0.100\n",
      "[80000] Loss: 0.0055 TrueN: 6 PredN: 5 HitNegN: 5 PredRew: 0.0163 ActRew: -0.0156 Eps: 0.100\n",
      "[80500] Loss: 0.0011 TrueN: 2 PredN: 2 HitNegN: 2 PredRew: 0.0361 ActRew: -0.0078 Eps: 0.100\n",
      "[81000] Loss: 0.0068 TrueN: 5 PredN: 2 HitNegN: 2 PredRew: 0.0437 ActRew: -0.0234 Eps: 0.100\n",
      "[81500] Loss: 0.0090 TrueN: 7 PredN: 4 HitNegN: 4 PredRew: 0.0117 ActRew: -0.0391 Eps: 0.100\n",
      "[82000] Loss: 0.0026 TrueN: 2 PredN: 1 HitNegN: 1 PredRew: 0.0431 ActRew: -0.0078 Eps: 0.100\n",
      "[82500] Loss: 0.0038 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: 0.0379 ActRew: -0.0156 Eps: 0.100\n",
      "[83000] Loss: 0.0026 TrueN: 7 PredN: 7 HitNegN: 7 PredRew: 0.0183 ActRew: -0.0312 Eps: 0.100\n",
      "[83500] Loss: 0.0098 TrueN: 2 PredN: 0 HitNegN: 0 PredRew: 0.0470 ActRew: -0.0078 Eps: 0.100\n",
      "[84000] Loss: 0.0052 TrueN: 1 PredN: 1 HitNegN: 1 PredRew: 0.0560 ActRew: 0.0000 Eps: 0.100\n",
      "[84500] Loss: 0.0015 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: 0.0133 ActRew: -0.0234 Eps: 0.100\n",
      "[85000] Loss: 0.0017 TrueN: 1 PredN: 1 HitNegN: 1 PredRew: 0.0256 ActRew: -0.0078 Eps: 0.100\n",
      "[85500] Loss: 0.0037 TrueN: 2 PredN: 2 HitNegN: 2 PredRew: 0.0586 ActRew: -0.0156 Eps: 0.100\n",
      "[86000] Loss: 0.0010 TrueN: 5 PredN: 5 HitNegN: 5 PredRew: 0.0130 ActRew: -0.0391 Eps: 0.100\n",
      "[86500] Loss: 0.0066 TrueN: 7 PredN: 5 HitNegN: 5 PredRew: 0.0638 ActRew: -0.0234 Eps: 0.100\n",
      "[87000] Loss: 0.0016 TrueN: 4 PredN: 3 HitNegN: 3 PredRew: 0.0516 ActRew: -0.0234 Eps: 0.100\n",
      "[87500] Loss: 0.0025 TrueN: 6 PredN: 6 HitNegN: 6 PredRew: 0.0094 ActRew: -0.0312 Eps: 0.100\n",
      "[88000] Loss: 0.0013 TrueN: 1 PredN: 1 HitNegN: 1 PredRew: 0.0653 ActRew: -0.0078 Eps: 0.100\n",
      "[88500] Loss: 0.0023 TrueN: 2 PredN: 2 HitNegN: 2 PredRew: 0.0522 ActRew: -0.0078 Eps: 0.100\n",
      "[89000] Loss: 0.0039 TrueN: 3 PredN: 2 HitNegN: 2 PredRew: 0.0272 ActRew: -0.0156 Eps: 0.100\n",
      "[89500] Loss: 0.0036 TrueN: 4 PredN: 3 HitNegN: 3 PredRew: 0.0403 ActRew: -0.0078 Eps: 0.100\n",
      "[90000] Loss: 0.0035 TrueN: 2 PredN: 1 HitNegN: 1 PredRew: 0.0341 ActRew: -0.0078 Eps: 0.100\n",
      "[90500] Loss: 0.0037 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: 0.0103 ActRew: -0.0156 Eps: 0.100\n",
      "[91000] Loss: 0.0019 TrueN: 2 PredN: 1 HitNegN: 1 PredRew: -0.0020 ActRew: -0.0078 Eps: 0.100\n",
      "[91500] Loss: 0.0019 TrueN: 2 PredN: 2 HitNegN: 2 PredRew: 0.0337 ActRew: -0.0156 Eps: 0.100\n",
      "[92000] Loss: 0.0033 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: 0.0159 ActRew: -0.0156 Eps: 0.100\n",
      "[92500] Loss: 0.0076 TrueN: 9 PredN: 8 HitNegN: 7 PredRew: -0.0013 ActRew: -0.0547 Eps: 0.100\n",
      "[93000] Loss: 0.0057 TrueN: 3 PredN: 1 HitNegN: 1 PredRew: -0.0016 ActRew: -0.0078 Eps: 0.100\n",
      "[93500] Loss: 0.0026 TrueN: 2 PredN: 2 HitNegN: 2 PredRew: 0.0300 ActRew: -0.0156 Eps: 0.100\n",
      "[94000] Loss: 0.0060 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: 0.0048 ActRew: -0.0234 Eps: 0.100\n",
      "[94500] Loss: 0.0034 TrueN: 3 PredN: 2 HitNegN: 2 PredRew: 0.0130 ActRew: -0.0156 Eps: 0.100\n",
      "[95000] Loss: 0.0025 TrueN: 2 PredN: 2 HitNegN: 2 PredRew: 0.0263 ActRew: -0.0078 Eps: 0.100\n",
      "[95500] Loss: 0.0068 TrueN: 2 PredN: 1 HitNegN: 1 PredRew: 0.0149 ActRew: -0.0156 Eps: 0.100\n",
      "[96000] Loss: 0.0026 TrueN: 6 PredN: 4 HitNegN: 4 PredRew: 0.0197 ActRew: -0.0312 Eps: 0.100\n",
      "[96500] Loss: 0.0050 TrueN: 6 PredN: 5 HitNegN: 4 PredRew: 0.0267 ActRew: -0.0312 Eps: 0.100\n",
      "[97000] Loss: 0.0042 TrueN: 4 PredN: 5 HitNegN: 4 PredRew: 0.0166 ActRew: -0.0312 Eps: 0.100\n",
      "[97500] Loss: 0.0062 TrueN: 6 PredN: 5 HitNegN: 5 PredRew: 0.0257 ActRew: -0.0312 Eps: 0.100\n",
      "[98000] Loss: 0.0058 TrueN: 6 PredN: 4 HitNegN: 4 PredRew: 0.0124 ActRew: -0.0156 Eps: 0.100\n",
      "[98500] Loss: 0.0025 TrueN: 5 PredN: 5 HitNegN: 5 PredRew: 0.0390 ActRew: -0.0234 Eps: 0.100\n",
      "[99000] Loss: 0.0022 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: 0.0079 ActRew: -0.0156 Eps: 0.100\n",
      "[99500] Loss: 0.0069 TrueN: 7 PredN: 6 HitNegN: 6 PredRew: -0.0149 ActRew: -0.0547 Eps: 0.100\n",
      "[100000] Loss: 0.0039 TrueN: 1 PredN: 1 HitNegN: 1 PredRew: 0.0586 ActRew: -0.0078 Eps: 0.100\n",
      "[100500] Loss: 0.0038 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: 0.0570 ActRew: -0.0156 Eps: 0.100\n",
      "[101000] Loss: 0.0028 TrueN: 5 PredN: 5 HitNegN: 5 PredRew: 0.0210 ActRew: -0.0234 Eps: 0.100\n",
      "[101500] Loss: 0.0081 TrueN: 6 PredN: 4 HitNegN: 4 PredRew: 0.0307 ActRew: -0.0312 Eps: 0.100\n",
      "[102000] Loss: 0.0045 TrueN: 6 PredN: 6 HitNegN: 6 PredRew: -0.0073 ActRew: -0.0469 Eps: 0.100\n",
      "[102500] Loss: 0.0032 TrueN: 1 PredN: 1 HitNegN: 1 PredRew: 0.0402 ActRew: 0.0000 Eps: 0.100\n",
      "[103000] Loss: 0.0097 TrueN: 5 PredN: 6 HitNegN: 5 PredRew: 0.0063 ActRew: -0.0391 Eps: 0.100\n",
      "[103500] Loss: 0.0016 TrueN: 5 PredN: 5 HitNegN: 5 PredRew: 0.0466 ActRew: -0.0391 Eps: 0.100\n",
      "[104000] Loss: 0.0059 TrueN: 5 PredN: 4 HitNegN: 4 PredRew: 0.0273 ActRew: -0.0234 Eps: 0.100\n",
      "[104500] Loss: 0.0030 TrueN: 8 PredN: 7 HitNegN: 7 PredRew: 0.0268 ActRew: -0.0391 Eps: 0.100\n",
      "[105000] Loss: 0.0036 TrueN: 7 PredN: 6 HitNegN: 6 PredRew: 0.0289 ActRew: -0.0469 Eps: 0.100\n",
      "[105500] Loss: 0.0099 TrueN: 7 PredN: 5 HitNegN: 5 PredRew: 0.0426 ActRew: -0.0469 Eps: 0.100\n",
      "[106000] Loss: 0.0023 TrueN: 3 PredN: 2 HitNegN: 2 PredRew: 0.0603 ActRew: -0.0078 Eps: 0.100\n",
      "[106500] Loss: 0.0027 TrueN: 1 PredN: 1 HitNegN: 1 PredRew: 0.0500 ActRew: 0.0000 Eps: 0.100\n",
      "[107000] Loss: 0.0030 TrueN: 6 PredN: 6 HitNegN: 6 PredRew: 0.0542 ActRew: -0.0234 Eps: 0.100\n",
      "[107500] Loss: 0.0049 TrueN: 6 PredN: 4 HitNegN: 4 PredRew: 0.0280 ActRew: -0.0312 Eps: 0.100\n",
      "[108000] Loss: 0.0067 TrueN: 9 PredN: 7 HitNegN: 7 PredRew: 0.0258 ActRew: -0.0312 Eps: 0.100\n",
      "[108500] Loss: 0.0015 TrueN: 7 PredN: 7 HitNegN: 7 PredRew: 0.0129 ActRew: -0.0547 Eps: 0.100\n",
      "[109000] Loss: 0.0024 TrueN: 2 PredN: 2 HitNegN: 2 PredRew: 0.0370 ActRew: -0.0078 Eps: 0.100\n",
      "[109500] Loss: 0.0031 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: 0.0636 ActRew: -0.0156 Eps: 0.100\n",
      "[110000] Loss: 0.0036 TrueN: 2 PredN: 3 HitNegN: 2 PredRew: 0.0633 ActRew: -0.0078 Eps: 0.100\n",
      "[110500] Loss: 0.0046 TrueN: 3 PredN: 2 HitNegN: 2 PredRew: 0.0820 ActRew: -0.0156 Eps: 0.100\n",
      "[111000] Loss: 0.0030 TrueN: 3 PredN: 2 HitNegN: 2 PredRew: 0.0386 ActRew: -0.0156 Eps: 0.100\n",
      "[111500] Loss: 0.0018 TrueN: 1 PredN: 1 HitNegN: 1 PredRew: 0.0879 ActRew: -0.0078 Eps: 0.100\n",
      "[112000] Loss: 0.0031 TrueN: 4 PredN: 3 HitNegN: 3 PredRew: 0.0645 ActRew: -0.0078 Eps: 0.100\n",
      "[112500] Loss: 0.0020 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: 0.0337 ActRew: -0.0156 Eps: 0.100\n",
      "[113000] Loss: 0.0055 TrueN: 2 PredN: 1 HitNegN: 1 PredRew: 0.0570 ActRew: -0.0078 Eps: 0.100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[113500] Loss: 0.0027 TrueN: 5 PredN: 5 HitNegN: 5 PredRew: 0.0162 ActRew: -0.0312 Eps: 0.100\n",
      "[114000] Loss: 0.0023 TrueN: 4 PredN: 4 HitNegN: 4 PredRew: 0.0529 ActRew: -0.0156 Eps: 0.100\n",
      "[114500] Loss: 0.0013 TrueN: 3 PredN: 4 HitNegN: 3 PredRew: 0.0664 ActRew: -0.0234 Eps: 0.100\n",
      "[115000] Loss: 0.0029 TrueN: 6 PredN: 5 HitNegN: 5 PredRew: 0.0349 ActRew: -0.0312 Eps: 0.100\n",
      "[115500] Loss: 0.0046 TrueN: 4 PredN: 2 HitNegN: 2 PredRew: 0.0762 ActRew: -0.0078 Eps: 0.100\n",
      "[116000] Loss: 0.0054 TrueN: 2 PredN: 2 HitNegN: 2 PredRew: 0.0619 ActRew: -0.0156 Eps: 0.100\n",
      "[116500] Loss: 0.0051 TrueN: 3 PredN: 4 HitNegN: 3 PredRew: 0.0666 ActRew: -0.0156 Eps: 0.100\n",
      "[117000] Loss: 0.0066 TrueN: 5 PredN: 3 HitNegN: 3 PredRew: 0.0482 ActRew: -0.0312 Eps: 0.100\n",
      "[117500] Loss: 0.0020 TrueN: 4 PredN: 4 HitNegN: 4 PredRew: 0.0822 ActRew: -0.0156 Eps: 0.100\n",
      "[118000] Loss: 0.0023 TrueN: 4 PredN: 4 HitNegN: 4 PredRew: 0.0627 ActRew: -0.0234 Eps: 0.100\n",
      "[118500] Loss: 0.0021 TrueN: 4 PredN: 4 HitNegN: 4 PredRew: 0.0499 ActRew: -0.0156 Eps: 0.100\n",
      "[119000] Loss: 0.0047 TrueN: 4 PredN: 3 HitNegN: 3 PredRew: -0.0098 ActRew: -0.0078 Eps: 0.100\n",
      "[119500] Loss: 0.0021 TrueN: 2 PredN: 2 HitNegN: 2 PredRew: 0.0682 ActRew: -0.0078 Eps: 0.100\n",
      "[120000] Loss: 0.0019 TrueN: 1 PredN: 1 HitNegN: 1 PredRew: 0.0731 ActRew: -0.0078 Eps: 0.100\n",
      "[120500] Loss: 0.0026 TrueN: 4 PredN: 4 HitNegN: 4 PredRew: 0.0794 ActRew: -0.0234 Eps: 0.100\n",
      "[121000] Loss: 0.0117 TrueN: 3 PredN: 1 HitNegN: 1 PredRew: 0.0856 ActRew: -0.0234 Eps: 0.100\n",
      "[121500] Loss: 0.0091 TrueN: 5 PredN: 4 HitNegN: 4 PredRew: 0.0561 ActRew: -0.0391 Eps: 0.100\n",
      "[122000] Loss: 0.0024 TrueN: 7 PredN: 7 HitNegN: 7 PredRew: 0.0716 ActRew: -0.0469 Eps: 0.100\n",
      "[122500] Loss: 0.0028 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: 0.0601 ActRew: -0.0234 Eps: 0.100\n",
      "[123000] Loss: 0.0055 TrueN: 1 PredN: 1 HitNegN: 1 PredRew: 0.0948 ActRew: -0.0078 Eps: 0.100\n",
      "[123500] Loss: 0.0049 TrueN: 2 PredN: 1 HitNegN: 1 PredRew: 0.0769 ActRew: -0.0156 Eps: 0.100\n",
      "[124000] Loss: 0.0040 TrueN: 3 PredN: 4 HitNegN: 3 PredRew: 0.1291 ActRew: -0.0156 Eps: 0.100\n",
      "[124500] Loss: 0.0039 TrueN: 3 PredN: 2 HitNegN: 2 PredRew: 0.1147 ActRew: -0.0078 Eps: 0.100\n",
      "[125000] Loss: 0.0066 TrueN: 7 PredN: 4 HitNegN: 4 PredRew: 0.0685 ActRew: -0.0391 Eps: 0.100\n",
      "[125500] Loss: 0.0030 TrueN: 2 PredN: 2 HitNegN: 2 PredRew: 0.0821 ActRew: -0.0078 Eps: 0.100\n",
      "[126000] Loss: 0.0029 TrueN: 1 PredN: 1 HitNegN: 1 PredRew: 0.0856 ActRew: -0.0078 Eps: 0.100\n",
      "[126500] Loss: 0.0017 TrueN: 3 PredN: 2 HitNegN: 2 PredRew: 0.0751 ActRew: -0.0156 Eps: 0.100\n",
      "[127000] Loss: 0.0060 TrueN: 3 PredN: 2 HitNegN: 2 PredRew: 0.0714 ActRew: -0.0078 Eps: 0.100\n",
      "[127500] Loss: 0.0022 TrueN: 5 PredN: 5 HitNegN: 5 PredRew: 0.0615 ActRew: -0.0234 Eps: 0.100\n",
      "[128000] Loss: 0.0071 TrueN: 6 PredN: 3 HitNegN: 3 PredRew: 0.0581 ActRew: -0.0234 Eps: 0.100\n",
      "[128500] Loss: 0.0058 TrueN: 2 PredN: 3 HitNegN: 2 PredRew: 0.0789 ActRew: -0.0156 Eps: 0.100\n",
      "[129000] Loss: 0.0021 TrueN: 2 PredN: 2 HitNegN: 2 PredRew: 0.0653 ActRew: -0.0078 Eps: 0.100\n",
      "[129500] Loss: 0.0045 TrueN: 5 PredN: 5 HitNegN: 5 PredRew: 0.0523 ActRew: -0.0312 Eps: 0.100\n",
      "[130000] Loss: 0.0023 TrueN: 2 PredN: 2 HitNegN: 2 PredRew: 0.0650 ActRew: -0.0078 Eps: 0.100\n",
      "[130500] Loss: 0.0028 TrueN: 4 PredN: 3 HitNegN: 3 PredRew: 0.0403 ActRew: -0.0234 Eps: 0.100\n",
      "[131000] Loss: 0.0041 TrueN: 1 PredN: 1 HitNegN: 1 PredRew: 0.0421 ActRew: -0.0078 Eps: 0.100\n",
      "[131500] Loss: 0.0028 TrueN: 6 PredN: 5 HitNegN: 5 PredRew: 0.0634 ActRew: -0.0391 Eps: 0.100\n",
      "[132000] Loss: 0.0051 TrueN: 2 PredN: 2 HitNegN: 2 PredRew: 0.0608 ActRew: -0.0078 Eps: 0.100\n",
      "[132500] Loss: 0.0051 TrueN: 3 PredN: 1 HitNegN: 1 PredRew: 0.0286 ActRew: -0.0156 Eps: 0.100\n",
      "[133000] Loss: 0.0095 TrueN: 3 PredN: 1 HitNegN: 1 PredRew: 0.0496 ActRew: -0.0234 Eps: 0.100\n",
      "[133500] Loss: 0.0095 TrueN: 4 PredN: 4 HitNegN: 3 PredRew: 0.0416 ActRew: -0.0312 Eps: 0.100\n",
      "[134000] Loss: 0.0025 TrueN: 6 PredN: 6 HitNegN: 6 PredRew: 0.0573 ActRew: -0.0156 Eps: 0.100\n",
      "[134500] Loss: 0.0034 TrueN: 4 PredN: 3 HitNegN: 3 PredRew: 0.0999 ActRew: -0.0234 Eps: 0.100\n",
      "[135000] Loss: 0.0083 TrueN: 7 PredN: 5 HitNegN: 5 PredRew: 0.0447 ActRew: -0.0234 Eps: 0.100\n",
      "[135500] Loss: 0.0016 TrueN: 4 PredN: 4 HitNegN: 4 PredRew: 0.0368 ActRew: -0.0234 Eps: 0.100\n",
      "[136000] Loss: 0.0027 TrueN: 1 PredN: 1 HitNegN: 1 PredRew: 0.1092 ActRew: -0.0078 Eps: 0.100\n",
      "[136500] Loss: 0.0022 TrueN: 1 PredN: 1 HitNegN: 1 PredRew: 0.0677 ActRew: -0.0078 Eps: 0.100\n",
      "[137000] Loss: 0.0013 TrueN: 4 PredN: 3 HitNegN: 3 PredRew: 0.0612 ActRew: -0.0156 Eps: 0.100\n",
      "[137500] Loss: 0.0023 TrueN: 0 PredN: 0 HitNegN: 0 PredRew: 0.0838 ActRew: 0.0000 Eps: 0.100\n",
      "[138000] Loss: 0.0037 TrueN: 11 PredN: 10 HitNegN: 10 PredRew: 0.0085 ActRew: -0.0391 Eps: 0.100\n",
      "[138500] Loss: 0.0019 TrueN: 5 PredN: 5 HitNegN: 5 PredRew: 0.0506 ActRew: -0.0312 Eps: 0.100\n",
      "[139000] Loss: 0.0087 TrueN: 3 PredN: 1 HitNegN: 1 PredRew: 0.0473 ActRew: -0.0234 Eps: 0.100\n",
      "[139500] Loss: 0.0034 TrueN: 2 PredN: 3 HitNegN: 2 PredRew: 0.0803 ActRew: -0.0156 Eps: 0.100\n",
      "[140000] Loss: 0.0032 TrueN: 2 PredN: 2 HitNegN: 2 PredRew: 0.0541 ActRew: -0.0156 Eps: 0.100\n",
      "[140500] Loss: 0.0028 TrueN: 4 PredN: 5 HitNegN: 4 PredRew: 0.0239 ActRew: -0.0234 Eps: 0.100\n",
      "[141000] Loss: 0.0052 TrueN: 7 PredN: 6 HitNegN: 6 PredRew: 0.0436 ActRew: -0.0469 Eps: 0.100\n",
      "[141500] Loss: 0.0026 TrueN: 6 PredN: 6 HitNegN: 5 PredRew: 0.0451 ActRew: -0.0234 Eps: 0.100\n",
      "[142000] Loss: 0.0027 TrueN: 3 PredN: 2 HitNegN: 2 PredRew: 0.0437 ActRew: -0.0156 Eps: 0.100\n",
      "[142500] Loss: 0.0065 TrueN: 11 PredN: 8 HitNegN: 8 PredRew: 0.0384 ActRew: -0.0547 Eps: 0.100\n",
      "[143000] Loss: 0.0022 TrueN: 5 PredN: 5 HitNegN: 5 PredRew: 0.0194 ActRew: -0.0312 Eps: 0.100\n",
      "[143500] Loss: 0.0027 TrueN: 2 PredN: 2 HitNegN: 2 PredRew: 0.0576 ActRew: -0.0078 Eps: 0.100\n",
      "[144000] Loss: 0.0136 TrueN: 5 PredN: 5 HitNegN: 3 PredRew: 0.0045 ActRew: -0.0312 Eps: 0.100\n",
      "[144500] Loss: 0.0040 TrueN: 5 PredN: 5 HitNegN: 5 PredRew: 0.0557 ActRew: -0.0391 Eps: 0.100\n",
      "[145000] Loss: 0.0046 TrueN: 6 PredN: 5 HitNegN: 5 PredRew: 0.0275 ActRew: -0.0234 Eps: 0.100\n",
      "[145500] Loss: 0.0043 TrueN: 5 PredN: 4 HitNegN: 4 PredRew: 0.0329 ActRew: -0.0312 Eps: 0.100\n",
      "[146000] Loss: 0.0024 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: 0.0498 ActRew: -0.0234 Eps: 0.100\n",
      "[146500] Loss: 0.0023 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: 0.0107 ActRew: -0.0234 Eps: 0.100\n",
      "[147000] Loss: 0.0033 TrueN: 0 PredN: 0 HitNegN: 0 PredRew: 0.0731 ActRew: 0.0000 Eps: 0.100\n",
      "[147500] Loss: 0.0026 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: 0.0764 ActRew: -0.0234 Eps: 0.100\n",
      "[148000] Loss: 0.0033 TrueN: 5 PredN: 5 HitNegN: 5 PredRew: 0.0854 ActRew: -0.0312 Eps: 0.100\n",
      "[148500] Loss: 0.0033 TrueN: 3 PredN: 2 HitNegN: 2 PredRew: 0.0279 ActRew: -0.0156 Eps: 0.100\n",
      "[149000] Loss: 0.0022 TrueN: 6 PredN: 6 HitNegN: 6 PredRew: 0.0407 ActRew: -0.0312 Eps: 0.100\n",
      "[149500] Loss: 0.0030 TrueN: 3 PredN: 4 HitNegN: 3 PredRew: 0.0607 ActRew: -0.0078 Eps: 0.100\n",
      "[150000] Loss: 0.0060 TrueN: 1 PredN: 3 HitNegN: 1 PredRew: 0.0728 ActRew: 0.0000 Eps: 0.100\n",
      "[150500] Loss: 0.0083 TrueN: 3 PredN: 1 HitNegN: 1 PredRew: 0.0673 ActRew: -0.0156 Eps: 0.100\n",
      "[151000] Loss: 0.0038 TrueN: 11 PredN: 10 HitNegN: 10 PredRew: -0.0093 ActRew: -0.0781 Eps: 0.100\n",
      "[151500] Loss: 0.0034 TrueN: 4 PredN: 4 HitNegN: 4 PredRew: 0.0684 ActRew: -0.0312 Eps: 0.100\n",
      "[152000] Loss: 0.0090 TrueN: 8 PredN: 6 HitNegN: 6 PredRew: 0.0532 ActRew: -0.0469 Eps: 0.100\n",
      "[152500] Loss: 0.0041 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: 0.0324 ActRew: -0.0156 Eps: 0.100\n",
      "[153000] Loss: 0.0025 TrueN: 4 PredN: 4 HitNegN: 4 PredRew: 0.0504 ActRew: -0.0156 Eps: 0.100\n",
      "[153500] Loss: 0.0019 TrueN: 2 PredN: 2 HitNegN: 2 PredRew: 0.0884 ActRew: -0.0156 Eps: 0.100\n",
      "[154000] Loss: 0.0024 TrueN: 2 PredN: 2 HitNegN: 2 PredRew: 0.0363 ActRew: -0.0156 Eps: 0.100\n",
      "[154500] Loss: 0.0039 TrueN: 4 PredN: 4 HitNegN: 4 PredRew: 0.0735 ActRew: -0.0312 Eps: 0.100\n",
      "[155000] Loss: 0.0052 TrueN: 4 PredN: 4 HitNegN: 4 PredRew: 0.0358 ActRew: -0.0156 Eps: 0.100\n",
      "[155500] Loss: 0.0024 TrueN: 2 PredN: 2 HitNegN: 2 PredRew: 0.0562 ActRew: -0.0156 Eps: 0.100\n",
      "[156000] Loss: 0.0021 TrueN: 5 PredN: 5 HitNegN: 5 PredRew: 0.0221 ActRew: -0.0391 Eps: 0.100\n",
      "[156500] Loss: 0.0053 TrueN: 4 PredN: 2 HitNegN: 2 PredRew: 0.0197 ActRew: -0.0156 Eps: 0.100\n",
      "[157000] Loss: 0.0052 TrueN: 2 PredN: 2 HitNegN: 2 PredRew: 0.0484 ActRew: -0.0156 Eps: 0.100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[157500] Loss: 0.0094 TrueN: 2 PredN: 2 HitNegN: 1 PredRew: 0.0571 ActRew: 0.0000 Eps: 0.100\n",
      "[158000] Loss: 0.0027 TrueN: 2 PredN: 2 HitNegN: 2 PredRew: 0.0633 ActRew: -0.0156 Eps: 0.100\n",
      "[158500] Loss: 0.0041 TrueN: 3 PredN: 2 HitNegN: 2 PredRew: 0.0743 ActRew: -0.0078 Eps: 0.100\n",
      "[159000] Loss: 0.0024 TrueN: 7 PredN: 7 HitNegN: 7 PredRew: 0.0629 ActRew: -0.0312 Eps: 0.100\n",
      "[159500] Loss: 0.0058 TrueN: 3 PredN: 1 HitNegN: 1 PredRew: 0.0255 ActRew: -0.0156 Eps: 0.100\n",
      "[160000] Loss: 0.0030 TrueN: 6 PredN: 5 HitNegN: 5 PredRew: 0.0173 ActRew: -0.0234 Eps: 0.100\n",
      "[160500] Loss: 0.0072 TrueN: 3 PredN: 1 HitNegN: 1 PredRew: 0.0665 ActRew: -0.0078 Eps: 0.100\n",
      "[161000] Loss: 0.0069 TrueN: 6 PredN: 5 HitNegN: 5 PredRew: -0.0227 ActRew: -0.0391 Eps: 0.100\n",
      "[161500] Loss: 0.0035 TrueN: 5 PredN: 4 HitNegN: 4 PredRew: 0.0188 ActRew: -0.0312 Eps: 0.100\n",
      "[162000] Loss: 0.0035 TrueN: 2 PredN: 2 HitNegN: 2 PredRew: 0.0362 ActRew: -0.0078 Eps: 0.100\n",
      "[162500] Loss: 0.0039 TrueN: 4 PredN: 5 HitNegN: 4 PredRew: -0.0055 ActRew: -0.0156 Eps: 0.100\n",
      "[163000] Loss: 0.0075 TrueN: 6 PredN: 6 HitNegN: 5 PredRew: 0.0215 ActRew: -0.0391 Eps: 0.100\n",
      "[163500] Loss: 0.0026 TrueN: 5 PredN: 4 HitNegN: 4 PredRew: 0.0045 ActRew: -0.0312 Eps: 0.100\n",
      "[164000] Loss: 0.0031 TrueN: 5 PredN: 5 HitNegN: 5 PredRew: 0.0483 ActRew: -0.0312 Eps: 0.100\n",
      "[164500] Loss: 0.0056 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: 0.0457 ActRew: -0.0156 Eps: 0.100\n",
      "[165000] Loss: 0.0030 TrueN: 2 PredN: 2 HitNegN: 2 PredRew: 0.0343 ActRew: -0.0156 Eps: 0.100\n",
      "[165500] Loss: 0.0037 TrueN: 8 PredN: 8 HitNegN: 8 PredRew: 0.0067 ActRew: -0.0469 Eps: 0.100\n",
      "[166000] Loss: 0.0109 TrueN: 4 PredN: 2 HitNegN: 2 PredRew: 0.0233 ActRew: -0.0312 Eps: 0.100\n",
      "[166500] Loss: 0.0039 TrueN: 4 PredN: 4 HitNegN: 4 PredRew: 0.0447 ActRew: -0.0156 Eps: 0.100\n",
      "[167000] Loss: 0.0043 TrueN: 3 PredN: 2 HitNegN: 2 PredRew: 0.0218 ActRew: -0.0156 Eps: 0.100\n",
      "[167500] Loss: 0.0035 TrueN: 7 PredN: 5 HitNegN: 5 PredRew: 0.0020 ActRew: -0.0156 Eps: 0.100\n",
      "[168000] Loss: 0.0026 TrueN: 4 PredN: 4 HitNegN: 4 PredRew: -0.0056 ActRew: -0.0156 Eps: 0.100\n",
      "[168500] Loss: 0.0037 TrueN: 4 PredN: 3 HitNegN: 3 PredRew: 0.0033 ActRew: -0.0156 Eps: 0.100\n",
      "[169000] Loss: 0.0067 TrueN: 7 PredN: 4 HitNegN: 4 PredRew: 0.0168 ActRew: -0.0078 Eps: 0.100\n",
      "[169500] Loss: 0.0042 TrueN: 4 PredN: 3 HitNegN: 3 PredRew: 0.0130 ActRew: -0.0156 Eps: 0.100\n",
      "[170000] Loss: 0.0028 TrueN: 5 PredN: 5 HitNegN: 5 PredRew: 0.0178 ActRew: -0.0312 Eps: 0.100\n",
      "[170500] Loss: 0.0120 TrueN: 5 PredN: 4 HitNegN: 3 PredRew: 0.0204 ActRew: -0.0234 Eps: 0.100\n",
      "[171000] Loss: 0.0033 TrueN: 6 PredN: 6 HitNegN: 6 PredRew: 0.0219 ActRew: -0.0312 Eps: 0.100\n",
      "[171500] Loss: 0.0054 TrueN: 3 PredN: 2 HitNegN: 2 PredRew: 0.0160 ActRew: 0.0000 Eps: 0.100\n",
      "[172000] Loss: 0.0029 TrueN: 5 PredN: 3 HitNegN: 2 PredRew: 0.0402 ActRew: -0.0078 Eps: 0.100\n",
      "[172500] Loss: 0.0032 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: 0.0394 ActRew: -0.0234 Eps: 0.100\n",
      "[173000] Loss: 0.0025 TrueN: 2 PredN: 2 HitNegN: 2 PredRew: 0.0547 ActRew: -0.0078 Eps: 0.100\n",
      "[173500] Loss: 0.0020 TrueN: 1 PredN: 1 HitNegN: 1 PredRew: 0.0340 ActRew: -0.0078 Eps: 0.100\n",
      "[174000] Loss: 0.0040 TrueN: 5 PredN: 5 HitNegN: 5 PredRew: 0.0156 ActRew: -0.0391 Eps: 0.100\n",
      "[174500] Loss: 0.0016 TrueN: 4 PredN: 3 HitNegN: 3 PredRew: 0.0245 ActRew: -0.0234 Eps: 0.100\n",
      "[175000] Loss: 0.0027 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: 0.0344 ActRew: -0.0156 Eps: 0.100\n",
      "[175500] Loss: 0.0047 TrueN: 7 PredN: 6 HitNegN: 6 PredRew: 0.0144 ActRew: -0.0391 Eps: 0.100\n",
      "[176000] Loss: 0.0025 TrueN: 4 PredN: 4 HitNegN: 4 PredRew: 0.0348 ActRew: -0.0312 Eps: 0.100\n",
      "[176500] Loss: 0.0077 TrueN: 2 PredN: 3 HitNegN: 2 PredRew: 0.0705 ActRew: -0.0156 Eps: 0.100\n",
      "[177000] Loss: 0.0089 TrueN: 5 PredN: 4 HitNegN: 4 PredRew: 0.0083 ActRew: -0.0234 Eps: 0.100\n",
      "[177500] Loss: 0.0021 TrueN: 6 PredN: 4 HitNegN: 4 PredRew: 0.0334 ActRew: -0.0312 Eps: 0.100\n",
      "[178000] Loss: 0.0084 TrueN: 2 PredN: 2 HitNegN: 1 PredRew: 0.0235 ActRew: -0.0156 Eps: 0.100\n",
      "[178500] Loss: 0.0143 TrueN: 6 PredN: 4 HitNegN: 4 PredRew: -0.0184 ActRew: -0.0312 Eps: 0.100\n",
      "[179000] Loss: 0.0025 TrueN: 2 PredN: 2 HitNegN: 2 PredRew: -0.0210 ActRew: -0.0156 Eps: 0.100\n",
      "[179500] Loss: 0.0048 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: 0.0134 ActRew: -0.0234 Eps: 0.100\n",
      "[180000] Loss: 0.0063 TrueN: 5 PredN: 2 HitNegN: 2 PredRew: 0.0212 ActRew: -0.0234 Eps: 0.100\n",
      "[180500] Loss: 0.0026 TrueN: 4 PredN: 4 HitNegN: 4 PredRew: 0.0263 ActRew: -0.0234 Eps: 0.100\n",
      "[181000] Loss: 0.0071 TrueN: 10 PredN: 7 HitNegN: 7 PredRew: -0.0103 ActRew: -0.0625 Eps: 0.100\n",
      "[181500] Loss: 0.0051 TrueN: 1 PredN: 2 HitNegN: 1 PredRew: 0.0031 ActRew: -0.0078 Eps: 0.100\n",
      "[182000] Loss: 0.0033 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: -0.0348 ActRew: -0.0234 Eps: 0.100\n",
      "[182500] Loss: 0.0024 TrueN: 2 PredN: 2 HitNegN: 2 PredRew: 0.0041 ActRew: -0.0078 Eps: 0.100\n",
      "[183000] Loss: 0.0047 TrueN: 6 PredN: 6 HitNegN: 6 PredRew: -0.0276 ActRew: -0.0469 Eps: 0.100\n",
      "[183500] Loss: 0.0029 TrueN: 5 PredN: 4 HitNegN: 4 PredRew: -0.0371 ActRew: -0.0312 Eps: 0.100\n",
      "[184000] Loss: 0.0048 TrueN: 4 PredN: 4 HitNegN: 4 PredRew: -0.0238 ActRew: -0.0156 Eps: 0.100\n",
      "[184500] Loss: 0.0016 TrueN: 1 PredN: 1 HitNegN: 1 PredRew: -0.0327 ActRew: -0.0078 Eps: 0.100\n",
      "[185000] Loss: 0.0065 TrueN: 5 PredN: 4 HitNegN: 4 PredRew: -0.0552 ActRew: -0.0234 Eps: 0.100\n",
      "[185500] Loss: 0.0023 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: -0.0648 ActRew: -0.0156 Eps: 0.100\n",
      "[186000] Loss: 0.0043 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: -0.0136 ActRew: -0.0078 Eps: 0.100\n",
      "[186500] Loss: 0.0042 TrueN: 3 PredN: 3 HitNegN: 2 PredRew: -0.0329 ActRew: -0.0078 Eps: 0.100\n",
      "[187000] Loss: 0.0062 TrueN: 2 PredN: 2 HitNegN: 1 PredRew: -0.0307 ActRew: -0.0156 Eps: 0.100\n",
      "[187500] Loss: 0.0041 TrueN: 7 PredN: 7 HitNegN: 7 PredRew: -0.0676 ActRew: -0.0547 Eps: 0.100\n",
      "[188000] Loss: 0.0037 TrueN: 4 PredN: 4 HitNegN: 4 PredRew: -0.1102 ActRew: -0.0312 Eps: 0.100\n",
      "[188500] Loss: 0.0046 TrueN: 5 PredN: 4 HitNegN: 4 PredRew: -0.0343 ActRew: -0.0312 Eps: 0.100\n",
      "[189000] Loss: 0.0059 TrueN: 8 PredN: 5 HitNegN: 5 PredRew: -0.0626 ActRew: -0.0391 Eps: 0.100\n",
      "[189500] Loss: 0.0043 TrueN: 2 PredN: 2 HitNegN: 2 PredRew: 0.0057 ActRew: -0.0156 Eps: 0.100\n",
      "[190000] Loss: 0.0021 TrueN: 1 PredN: 1 HitNegN: 1 PredRew: -0.0373 ActRew: -0.0078 Eps: 0.100\n",
      "[190500] Loss: 0.0051 TrueN: 9 PredN: 7 HitNegN: 7 PredRew: -0.0574 ActRew: -0.0312 Eps: 0.100\n",
      "[191000] Loss: 0.0025 TrueN: 8 PredN: 7 HitNegN: 7 PredRew: -0.0736 ActRew: -0.0391 Eps: 0.100\n",
      "[191500] Loss: 0.0068 TrueN: 4 PredN: 3 HitNegN: 3 PredRew: 0.0178 ActRew: -0.0312 Eps: 0.100\n",
      "[192000] Loss: 0.0057 TrueN: 7 PredN: 7 HitNegN: 7 PredRew: -0.0874 ActRew: -0.0391 Eps: 0.100\n",
      "[192500] Loss: 0.0079 TrueN: 8 PredN: 6 HitNegN: 6 PredRew: -0.0272 ActRew: -0.0469 Eps: 0.100\n",
      "[193000] Loss: 0.0056 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: -0.0523 ActRew: -0.0234 Eps: 0.100\n",
      "[193500] Loss: 0.0067 TrueN: 2 PredN: 1 HitNegN: 1 PredRew: -0.0221 ActRew: -0.0078 Eps: 0.100\n",
      "[194000] Loss: 0.0066 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: -0.0208 ActRew: -0.0156 Eps: 0.100\n",
      "[194500] Loss: 0.0096 TrueN: 6 PredN: 7 HitNegN: 6 PredRew: -0.0185 ActRew: -0.0234 Eps: 0.100\n",
      "[195000] Loss: 0.0043 TrueN: 5 PredN: 5 HitNegN: 5 PredRew: -0.0523 ActRew: -0.0234 Eps: 0.100\n",
      "[195500] Loss: 0.0042 TrueN: 4 PredN: 4 HitNegN: 4 PredRew: -0.0450 ActRew: -0.0312 Eps: 0.100\n",
      "[196000] Loss: 0.0033 TrueN: 6 PredN: 5 HitNegN: 5 PredRew: -0.0509 ActRew: -0.0234 Eps: 0.100\n",
      "[196500] Loss: 0.0043 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: -0.0309 ActRew: -0.0156 Eps: 0.100\n",
      "[197000] Loss: 0.0026 TrueN: 2 PredN: 2 HitNegN: 2 PredRew: -0.0385 ActRew: -0.0156 Eps: 0.100\n",
      "[197500] Loss: 0.0039 TrueN: 5 PredN: 5 HitNegN: 5 PredRew: -0.0681 ActRew: -0.0312 Eps: 0.100\n",
      "[198000] Loss: 0.0027 TrueN: 5 PredN: 4 HitNegN: 4 PredRew: -0.0072 ActRew: -0.0156 Eps: 0.100\n",
      "[198500] Loss: 0.0040 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: -0.0283 ActRew: -0.0156 Eps: 0.100\n",
      "[199000] Loss: 0.0022 TrueN: 7 PredN: 7 HitNegN: 7 PredRew: -0.0676 ActRew: -0.0391 Eps: 0.100\n",
      "[199500] Loss: 0.0028 TrueN: 1 PredN: 1 HitNegN: 1 PredRew: -0.0069 ActRew: -0.0078 Eps: 0.100\n",
      "[200000] Loss: 0.0038 TrueN: 10 PredN: 8 HitNegN: 8 PredRew: -0.0573 ActRew: -0.0391 Eps: 0.100\n",
      "[200500] Loss: 0.0029 TrueN: 5 PredN: 4 HitNegN: 4 PredRew: -0.0617 ActRew: -0.0156 Eps: 0.100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[201000] Loss: 0.0032 TrueN: 4 PredN: 4 HitNegN: 4 PredRew: 0.0078 ActRew: -0.0156 Eps: 0.100\n",
      "[201500] Loss: 0.0050 TrueN: 3 PredN: 4 HitNegN: 3 PredRew: -0.0312 ActRew: -0.0078 Eps: 0.100\n",
      "[202000] Loss: 0.0059 TrueN: 6 PredN: 4 HitNegN: 4 PredRew: 0.0029 ActRew: -0.0312 Eps: 0.100\n",
      "[202500] Loss: 0.0045 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: -0.0611 ActRew: -0.0078 Eps: 0.100\n",
      "[203000] Loss: 0.0059 TrueN: 7 PredN: 6 HitNegN: 6 PredRew: -0.0677 ActRew: -0.0469 Eps: 0.100\n",
      "[203500] Loss: 0.0055 TrueN: 6 PredN: 4 HitNegN: 4 PredRew: -0.0635 ActRew: -0.0312 Eps: 0.100\n",
      "[204000] Loss: 0.0030 TrueN: 4 PredN: 3 HitNegN: 3 PredRew: -0.0206 ActRew: -0.0156 Eps: 0.100\n",
      "[204500] Loss: 0.0050 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: -0.0049 ActRew: -0.0234 Eps: 0.100\n",
      "[205000] Loss: 0.0051 TrueN: 7 PredN: 7 HitNegN: 7 PredRew: -0.0222 ActRew: -0.0391 Eps: 0.100\n",
      "[205500] Loss: 0.0042 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: 0.0023 ActRew: -0.0156 Eps: 0.100\n",
      "[206000] Loss: 0.0084 TrueN: 4 PredN: 4 HitNegN: 3 PredRew: -0.0155 ActRew: -0.0078 Eps: 0.100\n",
      "[206500] Loss: 0.0041 TrueN: 3 PredN: 2 HitNegN: 2 PredRew: -0.0367 ActRew: -0.0078 Eps: 0.100\n",
      "[207000] Loss: 0.0035 TrueN: 0 PredN: 0 HitNegN: 0 PredRew: 0.0477 ActRew: 0.0000 Eps: 0.100\n",
      "[207500] Loss: 0.0102 TrueN: 3 PredN: 2 HitNegN: 2 PredRew: 0.0116 ActRew: -0.0156 Eps: 0.100\n",
      "[208000] Loss: 0.0042 TrueN: 6 PredN: 3 HitNegN: 3 PredRew: -0.0429 ActRew: -0.0234 Eps: 0.100\n",
      "[208500] Loss: 0.0084 TrueN: 8 PredN: 7 HitNegN: 6 PredRew: -0.0454 ActRew: -0.0234 Eps: 0.100\n",
      "[209000] Loss: 0.0045 TrueN: 3 PredN: 4 HitNegN: 3 PredRew: -0.0669 ActRew: -0.0156 Eps: 0.100\n",
      "[209500] Loss: 0.0084 TrueN: 7 PredN: 6 HitNegN: 6 PredRew: -0.0097 ActRew: -0.0547 Eps: 0.100\n",
      "[210000] Loss: 0.0019 TrueN: 5 PredN: 5 HitNegN: 5 PredRew: -0.0253 ActRew: -0.0312 Eps: 0.100\n",
      "[210500] Loss: 0.0031 TrueN: 2 PredN: 2 HitNegN: 2 PredRew: -0.0081 ActRew: -0.0078 Eps: 0.100\n",
      "[211000] Loss: 0.0054 TrueN: 6 PredN: 5 HitNegN: 5 PredRew: -0.0369 ActRew: -0.0234 Eps: 0.100\n",
      "[211500] Loss: 0.0034 TrueN: 5 PredN: 4 HitNegN: 4 PredRew: -0.0125 ActRew: -0.0156 Eps: 0.100\n",
      "[212000] Loss: 0.0030 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: 0.0093 ActRew: -0.0156 Eps: 0.100\n",
      "[212500] Loss: 0.0034 TrueN: 5 PredN: 5 HitNegN: 5 PredRew: 0.0124 ActRew: -0.0156 Eps: 0.100\n",
      "[213000] Loss: 0.0031 TrueN: 5 PredN: 3 HitNegN: 3 PredRew: -0.0139 ActRew: -0.0234 Eps: 0.100\n",
      "[213500] Loss: 0.0080 TrueN: 7 PredN: 6 HitNegN: 6 PredRew: -0.0403 ActRew: -0.0391 Eps: 0.100\n",
      "[214000] Loss: 0.0105 TrueN: 6 PredN: 4 HitNegN: 4 PredRew: -0.0111 ActRew: -0.0391 Eps: 0.100\n",
      "[214500] Loss: 0.0021 TrueN: 1 PredN: 0 HitNegN: 0 PredRew: -0.0483 ActRew: 0.0000 Eps: 0.100\n",
      "[215000] Loss: 0.0092 TrueN: 4 PredN: 3 HitNegN: 2 PredRew: -0.0088 ActRew: -0.0156 Eps: 0.100\n",
      "[215500] Loss: 0.0029 TrueN: 2 PredN: 1 HitNegN: 1 PredRew: -0.0203 ActRew: 0.0000 Eps: 0.100\n",
      "[216000] Loss: 0.0027 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: -0.0161 ActRew: -0.0234 Eps: 0.100\n",
      "[216500] Loss: 0.0037 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: -0.0169 ActRew: -0.0078 Eps: 0.100\n",
      "[217000] Loss: 0.0031 TrueN: 4 PredN: 4 HitNegN: 4 PredRew: -0.0203 ActRew: -0.0234 Eps: 0.100\n",
      "[217500] Loss: 0.0021 TrueN: 1 PredN: 1 HitNegN: 1 PredRew: -0.0143 ActRew: -0.0078 Eps: 0.100\n",
      "[218000] Loss: 0.0038 TrueN: 2 PredN: 0 HitNegN: 0 PredRew: -0.0182 ActRew: 0.0000 Eps: 0.100\n",
      "[218500] Loss: 0.0037 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: -0.0613 ActRew: -0.0234 Eps: 0.100\n",
      "[219000] Loss: 0.0082 TrueN: 7 PredN: 5 HitNegN: 5 PredRew: -0.0450 ActRew: -0.0391 Eps: 0.100\n",
      "[219500] Loss: 0.0017 TrueN: 2 PredN: 2 HitNegN: 2 PredRew: -0.0404 ActRew: -0.0078 Eps: 0.100\n",
      "[220000] Loss: 0.0039 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: -0.0144 ActRew: -0.0156 Eps: 0.100\n",
      "[220500] Loss: 0.0063 TrueN: 4 PredN: 2 HitNegN: 2 PredRew: 0.0012 ActRew: -0.0234 Eps: 0.100\n",
      "[221000] Loss: 0.0035 TrueN: 1 PredN: 1 HitNegN: 1 PredRew: -0.0075 ActRew: 0.0000 Eps: 0.100\n",
      "[221500] Loss: 0.0027 TrueN: 4 PredN: 4 HitNegN: 4 PredRew: -0.0295 ActRew: -0.0156 Eps: 0.100\n",
      "[222000] Loss: 0.0117 TrueN: 6 PredN: 3 HitNegN: 3 PredRew: 0.0060 ActRew: -0.0312 Eps: 0.100\n",
      "[222500] Loss: 0.0057 TrueN: 6 PredN: 6 HitNegN: 6 PredRew: -0.0318 ActRew: -0.0469 Eps: 0.100\n",
      "[223000] Loss: 0.0098 TrueN: 2 PredN: 1 HitNegN: 1 PredRew: 0.0180 ActRew: -0.0156 Eps: 0.100\n",
      "[223500] Loss: 0.0069 TrueN: 3 PredN: 3 HitNegN: 2 PredRew: -0.0157 ActRew: -0.0156 Eps: 0.100\n",
      "[224000] Loss: 0.0113 TrueN: 4 PredN: 4 HitNegN: 3 PredRew: -0.0275 ActRew: -0.0234 Eps: 0.100\n",
      "[224500] Loss: 0.0042 TrueN: 4 PredN: 4 HitNegN: 4 PredRew: -0.0366 ActRew: -0.0312 Eps: 0.100\n",
      "[225000] Loss: 0.0038 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: 0.0096 ActRew: -0.0234 Eps: 0.100\n",
      "[225500] Loss: 0.0027 TrueN: 7 PredN: 7 HitNegN: 7 PredRew: -0.0104 ActRew: -0.0312 Eps: 0.100\n",
      "[226000] Loss: 0.0099 TrueN: 5 PredN: 2 HitNegN: 2 PredRew: 0.0437 ActRew: -0.0234 Eps: 0.100\n",
      "[226500] Loss: 0.0059 TrueN: 5 PredN: 4 HitNegN: 4 PredRew: -0.0202 ActRew: -0.0156 Eps: 0.100\n",
      "[227000] Loss: 0.0035 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: 0.0214 ActRew: -0.0078 Eps: 0.100\n",
      "[227500] Loss: 0.0016 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: -0.0054 ActRew: -0.0156 Eps: 0.100\n",
      "[228000] Loss: 0.0095 TrueN: 4 PredN: 3 HitNegN: 3 PredRew: 0.0259 ActRew: -0.0234 Eps: 0.100\n",
      "[228500] Loss: 0.0075 TrueN: 5 PredN: 3 HitNegN: 3 PredRew: 0.0043 ActRew: -0.0156 Eps: 0.100\n",
      "[229000] Loss: 0.0055 TrueN: 5 PredN: 5 HitNegN: 5 PredRew: -0.0371 ActRew: -0.0234 Eps: 0.100\n",
      "[229500] Loss: 0.0083 TrueN: 4 PredN: 1 HitNegN: 1 PredRew: -0.0050 ActRew: -0.0078 Eps: 0.100\n",
      "[230000] Loss: 0.0022 TrueN: 1 PredN: 1 HitNegN: 1 PredRew: -0.0124 ActRew: -0.0078 Eps: 0.100\n",
      "[230500] Loss: 0.0087 TrueN: 5 PredN: 4 HitNegN: 4 PredRew: 0.0023 ActRew: -0.0312 Eps: 0.100\n",
      "[231000] Loss: 0.0020 TrueN: 1 PredN: 1 HitNegN: 1 PredRew: -0.0182 ActRew: 0.0000 Eps: 0.100\n",
      "[231500] Loss: 0.0063 TrueN: 6 PredN: 6 HitNegN: 6 PredRew: 0.0019 ActRew: -0.0234 Eps: 0.100\n",
      "[232000] Loss: 0.0028 TrueN: 4 PredN: 2 HitNegN: 2 PredRew: 0.0086 ActRew: -0.0078 Eps: 0.100\n",
      "[232500] Loss: 0.0019 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: -0.0223 ActRew: -0.0156 Eps: 0.100\n",
      "[233000] Loss: 0.0105 TrueN: 4 PredN: 4 HitNegN: 2 PredRew: -0.0045 ActRew: -0.0156 Eps: 0.100\n",
      "[233500] Loss: 0.0033 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: -0.0242 ActRew: -0.0078 Eps: 0.100\n",
      "[234000] Loss: 0.0044 TrueN: 1 PredN: 1 HitNegN: 1 PredRew: 0.0233 ActRew: 0.0000 Eps: 0.100\n",
      "[234500] Loss: 0.0047 TrueN: 3 PredN: 3 HitNegN: 3 PredRew: -0.0115 ActRew: -0.0156 Eps: 0.100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-6b4e0c8d8d0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mK\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mnew_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_obs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mctrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactionmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_term\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-12afa898efdc>\u001b[0m in \u001b[0;36mobserve\u001b[0;34m(self, new_obs, action, reward, is_terminal)\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-12afa898efdc>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mterm_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSHORT_MEMORY_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0mstate_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m                 \u001b[0mnext_state_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "actionmax = 0\n",
    "for e in range(1000000):\n",
    "    if e % K == 0:\n",
    "        actionmax = ctrl.get_action()\n",
    "    new_obs, reward, is_term, _ = env.step(actionmax)\n",
    "    if is_term:\n",
    "        new_obs = env.reset()\n",
    "        \n",
    "    if e % K == 0:\n",
    "        new_obs = preprocess(new_obs).squeeze()\n",
    "        ctrl.observe(new_obs, actionmax, reward, is_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: 0.0, terminal?: False\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANEAAAD8CAYAAADpCEEHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyCzJITJLcojMkhwis6T/B/x9QNcflpU1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "act = act_idle\n",
    "# act = act_up\n",
    "# act = act_down\n",
    "obs, reward, is_term, _ = env.step(act)\n",
    "print('Reward: {}, terminal?: {}'.format(reward, is_term))\n",
    "show(preprocess(obs))\n",
    "show(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANEAAAD8CAYAAADpCEEHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nySEyS3KIzJIcIrMkh8gs6f8Bp+lHgv4UmYQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
