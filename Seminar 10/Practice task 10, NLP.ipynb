{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Семинар 10: \"Генерация текстов\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ФИО: Дорожинский Владислав Игоревич"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_sequence\n",
    "from torch.nn.utils.rnn import pad_packed_sequence\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import sys\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот семинар посвящен чат-ботам. Вам предстоит реализовать модель, генерирующую определенные тексты. В качестве текстов можно взять сборник цитат умных людей, предсказаний и т.д. На семинаре мы используем данные https://github.com/alvations/Quotables/blob/master/author-quote.txt\n",
    "\n",
    "При реализации задания вы можете пользоваться кодом из этого примера: <a href=https://github.com/spro/practical-pytorch/blob/master/char-rnn-generation/char-rnn-generation.ipynb>Generating Shakespeare with a Character-Level RNN</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 1: подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте датасет для дальнейшего обучения (будем использовать batch size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A. A. Milne\tIf you live to be a hundred, I want to live to be a hundred minus one day so I never have to live without you.\r\n",
      "A. A. Milne\tPromise me you'll always remember: You're braver than you believe, and stronger than you seem, and smarter than you think.\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 2 author-quote.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines = [x.split('\\t')[1].strip() for x in open('author-quote.txt').readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = map(len, lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQJIqZQKQpEqZACSpUiYASarU/wMzEEUnDA+ZHgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(list(map(len, lines)), bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "line = lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If you live to be a hundred, I want to live to be a hundred minus one day so I never have to live without you.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines = list(filter(lambda x: len(x) <= 50, lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "    def __init__(self, sentences):\n",
    "        all_characters = set()\n",
    "        for line in sentences:\n",
    "            all_characters |= set(line)\n",
    "        all_characters = list(all_characters)+['<eos>', '<go>']\n",
    "        self.char_to_id = {x[1]:x[0] for x in enumerate(all_characters)}\n",
    "        self.id_to_char = {x[0]:x[1] for x in enumerate(all_characters)}\n",
    "        self.size = len(all_characters)\n",
    "\n",
    "    def encode(self, line):\n",
    "        return np.array([self.char_to_id[x] for x in line])\n",
    "    \n",
    "    def decode(self, tokens):\n",
    "        return ''.join([self.id_to_char[x] for x in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = Vocabulary(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert vocab.decode(vocab.encode(lines[0])) == lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Quotes(Dataset):\n",
    "    def __init__(self, sentences, vocab):\n",
    "        # Construct vocabulary + EOS & GO tokens\n",
    "        self.sentences = sentences\n",
    "        self.vocab = vocab\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        input = self.vocab.encode(['<go>'] + list(self.sentences[idx]))\n",
    "        output = self.vocab.encode(list(self.sentences[idx])+['<eos>'])\n",
    "        return input, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = Quotes(lines, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(a):\n",
    "    X = np.empty(len(a), dtype=np.object)\n",
    "    Y = np.empty(len(a), dtype=np.object)\n",
    "    for i, (x, y) in enumerate(a):\n",
    "        X[i] = x\n",
    "        Y[i] = y\n",
    "    return X, Y\n",
    "\n",
    "dataloader = DataLoader(dataset, shuffle=True, batch_size=128, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 2: определение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Oracle(nn.Module):\n",
    "    def __init__(self, vocabulary_size, embedding_size=128, hidden_size=256, layers=2):\n",
    "        super(Oracle, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.layers = layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(vocabulary_size, embedding_size)\n",
    "        self.generator = nn.GRU(embedding_size, hidden_size, layers, batch_first=True)\n",
    "        self.classifier = nn.Linear(hidden_size, vocabulary_size)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        embeddings = [self.embedding(e) for e in input]\n",
    "        bs = len(input)\n",
    "        seq = pack_sequence(embeddings)\n",
    "        h = Variable(torch.Tensor(self.layers, bs, self.hidden_size).normal_(), requires_grad=False)*0\n",
    "        output, _ = self.generator(seq, h.cuda())\n",
    "        output, lengths = pad_packed_sequence(output)\n",
    "        max_len = len(input[0])\n",
    "        classes = self.classifier(output.view(bs*max_len, -1)).view(max_len, bs, -1)\n",
    "        mask = torch.zeros((max_len, bs, 1)).cuda()\n",
    "        for i in range(bs):\n",
    "            mask[0:lengths[i],i] = 1\n",
    "        classes = classes * mask\n",
    "        return classes, lengths\n",
    "    \n",
    "    def generate(self, vocab, max_len=100, T=1.0):\n",
    "        h = Variable(torch.Tensor(self.layers, 1, self.hidden_size).normal_(), requires_grad=False)*0\n",
    "        current_token = '<go>'\n",
    "        line = ''\n",
    "        while (current_token != '<eos>') and len(line) < max_len:\n",
    "            token = torch.Tensor([[vocab.char_to_id[current_token]]]).long()\n",
    "            token_id = Variable(token, volatile=True).cuda()\n",
    "            embedding = self.embedding(token_id)\n",
    "            output, (h) = self.generator(embedding, h.cuda())\n",
    "            classes = self.classifier(output[0])\n",
    "            probs = classes.data.cpu().numpy().reshape(-1) / T\n",
    "            probs = np.exp(probs - np.max(probs)) / np.sum(np.exp(probs - np.max(probs)))\n",
    "            new_token_id = np.random.choice(probs.shape[0], size=1, p=probs)[0]\n",
    "            current_token = vocab.id_to_char[new_token_id]\n",
    "            line = line + current_token\n",
    "        return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oracle = Oracle(vocab.size, embedding_size=32, hidden_size=128, layers=2).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 3: обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(oracle.parameters(), lr=0.01, betas=(0, 0.9))\n",
    "scheduler = ReduceLROnPlateau(optimizer, factor=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Documents/MachineLearning/mlenv/lib/python3.5/site-packages/ipykernel_launcher.py:32: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 200: 3.123282786073356 A maythe Wor is the is the papthe are mary is the athe hathe sors is norathe ther ofare.<eos>\n",
      "4 / 200: 2.2033673237110007 Chore Lishion is the streat with is the historion is the reverest of the you word.<eos>\n",
      "8 / 200: 2.0356811737192086 I am fool many for ever to be a contrack.<eos>\n",
      "12 / 200: 1.9402615982910683 I have not like rid for the money.<eos>\n",
      "16 / 200: 1.8926346836418941 I do in Grood a progress and the Jappier.<eos>\n",
      "20 / 200: 1.8480717025954148 I like that change is a big puts it is the life.<eos>\n",
      "24 / 200: 1.8250803207529003 I love song is a power my soot for of ideal that prove for everything.<eos>\n",
      "28 / 200: 1.8158446262622703 What we are some gone should be.<eos>\n",
      "32 / 200: 1.8076709508895874 By past should eat to lose who are not fruings.<eos>\n",
      "36 / 200: 1.8052310203683788 The first did, I try to love by accident.<eos>\n",
      "40 / 200: 1.7986955067207073 I've always been on my delader.<eos>\n",
      "44 / 200: 1.8058188126004975 I'm free free prockencieled in the secreted.<eos>\n",
      "48 / 200: 1.6837080799300095 A friend is a long law in a character.<eos>\n",
      "52 / 200: 1.6268627314731992 I don't have a sense of the less.<eos>\n",
      "56 / 200: 1.5905388059287235 I don't like to do business of bed, the leader in Belle &ish.<eos>\n",
      "60 / 200: 1.5720444383292362 I think an Ewsoned you do much of great.<eos>\n",
      "64 / 200: 1.557058338461251 I think women have words, but I can be seen of beauty.<eos>\n",
      "68 / 200: 1.542195172145449 I love to write my contend with starting more than a rome.<eos>\n",
      "72 / 200: 1.535535298544785 The purpose of a happy maskerly famous before I knew my or do.<eos>\n",
      "76 / 200: 1.5244205737936085 I was always whole not mad. Stame lacrul.<eos>\n",
      "80 / 200: 1.5160220039301906 I like to stop period hating refuse than movies.<eos>\n",
      "84 / 200: 1.5073072828095535 For the past, I was trained.<eos>\n",
      "88 / 200: 1.5072224386807145 The best musing in yourself with a wise.<eos>\n",
      "92 / 200: 1.502604866849965 I can't tannatortain about my life.<eos>\n",
      "96 / 200: 1.4980203940950592 We called if you miss an awe Know what to have a child without opportunity.<eos>\n",
      "100 / 200: 1.4924619115632156 The best reverated in the speed of life.<eos>\n",
      "104 / 200: 1.4892373578301792 I don't pair to take a play work.<eos>\n",
      "108 / 200: 1.4893669835452377 The puts the price for the heart to choose will be.<eos>\n",
      "112 / 200: 1.4864598142689671 I'm not a story of my wife is a pretty insecure of history.<eos>\n",
      "116 / 200: 1.4891431331634521 I'm fiercely grateful.<eos>\n",
      "120 / 200: 1.4827144104858925 I believe in politics.<eos>\n",
      "124 / 200: 1.4815291495158756 It's more being when I'm improved.<eos>\n",
      "128 / 200: 1.4813751968844184 Even always strives to live to excelles.<eos>\n",
      "132 / 200: 1.4850229107100388 I can't ear expensive twincipess.<eos>\n",
      "136 / 200: 1.4747617861320232 I can't really air twice me.<eos>\n",
      "140 / 200: 1.4776976807364102 I want to be a real will clear.<eos>\n",
      "144 / 200: 1.4792201025732632 I like to do a mistake.<eos>\n",
      "148 / 200: 1.4220079306898445 I was a guy the Democratic way.<eos>\n",
      "152 / 200: 1.3465688721886997 I love being a line is really an lone.<eos>\n",
      "156 / 200: 1.335260321354044 I love to write does not become anyone democracy and books.<eos>\n",
      "160 / 200: 1.322047574766751 I was always try thing time failure.<eos>\n",
      "164 / 200: 1.3144494089586982 I like things simple.<eos>\n",
      "168 / 200: 1.3077994913890445 I have a strong protion of all knowledge laughon.<eos>\n",
      "172 / 200: 1.3047524402881492 I like writing at all is to made guys.<eos>\n",
      "176 / 200: 1.2993520210529197 I don't have to be funny than which is a very much.<eos>\n",
      "180 / 200: 1.2946431965663516 I love happilying on my ideal deed.<eos>\n",
      "184 / 200: 1.2940044279756218 I was a sexist end.<eos>\n",
      "188 / 200: 1.285102733250322 I have a ladioler the difficult.<eos>\n",
      "192 / 200: 1.2841227588982418 I love the girl never saw my wife.<eos>\n",
      "196 / 200: 1.279026853627172 I'm not keen on the bunnying to be funny.<eos>\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 200\n",
    "for epoch in range(n_epochs):\n",
    "    losses = []\n",
    "    for i, (x, y) in enumerate(dataloader):\n",
    "        lengths = [len(s) for s in x]\n",
    "        order = np.argsort(lengths)[::-1]\n",
    "        x = x[order]\n",
    "        y = y[order]\n",
    "        x = [Variable(torch.tensor(s)).cuda() for s in x]\n",
    "        y = [Variable(torch.tensor(s)).cuda() for s in y]\n",
    "        y = pad_packed_sequence(pack_sequence(y))[0].view(-1)\n",
    "        \n",
    "        prediction, lengths = oracle(x)\n",
    "        loss = criterion(prediction.view(-1, vocab.size), y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        oracle.zero_grad()\n",
    "        losses.append(loss.item())\n",
    "    scheduler.step(np.mean(losses))\n",
    "    if epoch % 4 == 0:\n",
    "        print('{} / {}:'.format(epoch, n_epochs), np.mean(losses), oracle.generate(vocab, T=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 4: оценивание модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> Приведите примеры сгенерированных предложений </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It is impossible to love and married, by win.<eos>'"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oracle.generate(vocab, T=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The greatest gift in life is to seell mind.<eos>'"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oracle.generate(vocab, T=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm not gonna be a person, not for it.<eos>\""
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oracle.generate(vocab, T=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feedback (опционально)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь вы можете оставить список опечаток из лекции или семинара:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь вы можете оставить комментарии по лекции или семинару:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
